2022-01-09T11:41:37,844 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T11:41:37,844 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T11:41:37,940 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T11:41:37,940 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T11:41:37,948 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T11:41:37,948 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T11:41:37,973 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T11:41:37,973 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T11:41:38,673 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T11:41:38,673 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T11:41:38,674 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T11:41:38,674 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T11:41:38,674 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T11:41:38,674 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T11:41:38,676 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T11:41:38,676 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T11:41:38,696 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T11:41:38,696 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T11:41:38,709 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T11:41:38,709 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T11:41:40,096 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T11:41:40,096 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T11:41:40,096 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T11:41:40,096 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T11:41:40,097 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T11:41:40,097 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T11:41:40,097 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T11:41:40,097 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T11:41:40,099 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T11:41:40,099 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T11:41:40,104 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T11:41:40,104 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T11:41:40,219 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T11:41:40,219 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T11:41:40,220 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T11:41:40,220 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T11:41:40,223 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T11:41:40,223 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T11:41:40,224 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T11:41:40,224 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T11:41:40,239 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T11:41:40,239 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T11:41:40,701 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T11:41:40,701 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T11:41:40,837 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:pressler-dell,timestamp:1641724900
2022-01-09T11:41:40,840 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.28519821166992|#Level:Host|#hostname:pressler-dell,timestamp:1641724900
2022-01-09T11:41:40,846 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9685401916504|#Level:Host|#hostname:pressler-dell,timestamp:1641724900
2022-01-09T11:41:40,848 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641724900
2022-01-09T11:41:40,849 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:23248.53515625|#Level:Host|#hostname:pressler-dell,timestamp:1641724900
2022-01-09T11:41:40,849 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:5807.75|#Level:Host|#hostname:pressler-dell,timestamp:1641724900
2022-01-09T11:41:40,851 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:27.2|#Level:Host|#hostname:pressler-dell,timestamp:1641724900
2022-01-09T11:41:40,929 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T11:41:40,932 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]57422
2022-01-09T11:41:40,934 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T11:41:40,934 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T11:41:40,943 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T11:41:40,944 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T11:41:40,954 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T11:41:40,954 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T11:41:40,974 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T11:41:40,991 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641724900991
2022-01-09T11:41:40,991 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641724900991
2022-01-09T11:41:41,095 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T11:41:41,321 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T11:41:41,322 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]57435
2022-01-09T11:41:41,323 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T11:41:41,323 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T11:41:41,323 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T11:41:41,324 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T11:41:41,323 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T11:41:41,323 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T11:41:41,332 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T11:41:41,333 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641724901333
2022-01-09T11:41:41,333 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641724901333
2022-01-09T11:41:41,416 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T11:41:42,334 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1223
2022-01-09T11:41:42,334 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1223
2022-01-09T11:41:42,334 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T11:41:42,334 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T11:41:42,334 [INFO ] W-9000-scalenet_1.0 TS_METRICS - W-9000-scalenet_1.0.ms:3651|#Level:Host|#hostname:pressler-dell,timestamp:1641724902
2022-01-09T11:41:42,335 [INFO ] W-9000-scalenet_1.0 TS_METRICS - WorkerThreadTime.ms:121|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T11:41:46,993 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T11:41:46,994 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T11:41:47,040 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T11:41:47,042 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T11:41:47,502 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T11:41:47,504 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T11:41:47,506 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 224 layers, 7056607 parameters, 7056607 gradients, 16.3 GFLOPS
2022-01-09T11:41:47,508 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T11:41:47,509 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model file /tmp/models/a9ba2de5d2ee40db915896fd7fac0adc/yolov5s.pt loaded successfully
2022-01-09T11:41:47,510 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6100
2022-01-09T11:41:47,510 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6100
2022-01-09T11:41:47,510 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T11:41:47,510 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T11:41:47,510 [INFO ] W-9001-yolov5_0.1 TS_METRICS - W-9001-yolov5_0.1.ms:7413|#Level:Host|#hostname:pressler-dell,timestamp:1641724907
2022-01-09T11:41:47,511 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:78|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T11:42:14,201 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641724934201
2022-01-09T11:42:14,201 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641724934201
2022-01-09T11:42:14,222 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641724934
2022-01-09T11:42:14,462 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - tensor([[1318.59924,  203.64111, 1585.54492,  759.35504],
2022-01-09T11:42:14,464 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 242
2022-01-09T11:42:14,463 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [ 508.02631,  266.97983,  715.44958,  886.97882],
2022-01-09T11:42:14,465 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [ 915.31384,  288.95682, 1022.94250,  462.12167],
2022-01-09T11:42:14,465 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [1288.83057,  170.32613, 1459.75818,  292.86652],
2022-01-09T11:42:14,466 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [1198.20520,  264.37381, 1331.99744,  511.24484],
2022-01-09T11:42:14,467 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [ 506.21530,  243.98222,  592.34570,  321.41556],
2022-01-09T11:42:14,464 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 242
2022-01-09T11:42:14,467 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [1528.31519,  383.71832, 1693.92505,  556.65479],
2022-01-09T11:42:14,473 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [   9.94417,  182.75980,  116.38648,  254.74619],
2022-01-09T11:42:14,474 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [1642.52563,  307.39008, 1750.79846,  380.56555],
2022-01-09T11:42:14,474 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [1602.39478,  377.57782, 1725.39185,  544.04309],
2022-01-09T11:42:14,475 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [ 660.53363,  287.25793,  759.11249,  335.33014],
2022-01-09T11:42:14,475 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [  10.94354,  183.42285,  117.14539,  254.28714],
2022-01-09T11:42:14,475 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [ 426.42984,  257.66620,  515.22424,  364.65668]], device='cuda:0')
2022-01-09T11:42:14,476 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - tensor([[ 559.15881,  305.92285,  634.93896,  386.12317],
2022-01-09T11:42:14,476 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [1481.50989,  227.25751, 1542.32336,  289.98309]], device='cuda:0')
2022-01-09T11:42:14,477 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - tensor([[0.00000, 0.04726, 0.00000, 0.00000, 0.00000, 0.04203, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000],
2022-01-09T11:42:14,477 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [0.02571, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000, 0.00000]], device='cuda:0')
2022-01-09T11:42:14,477 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - tensor([1, 0], device='cuda:0')
2022-01-09T11:42:14,478 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model: yolov5, Invalid return type: <class 'NoneType'>.
2022-01-09T11:42:14,483 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:53760 "POST /predictions/yolov5 HTTP/1.1" 503 440
2022-01-09T11:42:14,485 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T11:42:14,486 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 226203, Inference time ns: 285639393
2022-01-09T11:42:14,486 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 226203, Inference time ns: 285639393
2022-01-09T11:42:14,486 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:43|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T11:42:40,766 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641724960
2022-01-09T11:42:40,766 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.2848129272461|#Level:Host|#hostname:pressler-dell,timestamp:1641724960
2022-01-09T11:42:40,767 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9689254760742|#Level:Host|#hostname:pressler-dell,timestamp:1641724960
2022-01-09T11:42:40,768 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641724960
2022-01-09T11:42:40,770 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20572.1328125|#Level:Host|#hostname:pressler-dell,timestamp:1641724960
2022-01-09T11:42:40,771 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8342.71875|#Level:Host|#hostname:pressler-dell,timestamp:1641724960
2022-01-09T11:42:40,771 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:35.6|#Level:Host|#hostname:pressler-dell,timestamp:1641724960
2022-01-09T11:43:40,765 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725020
2022-01-09T11:43:40,765 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.2848014831543|#Level:Host|#hostname:pressler-dell,timestamp:1641725020
2022-01-09T11:43:40,765 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.968936920166|#Level:Host|#hostname:pressler-dell,timestamp:1641725020
2022-01-09T11:43:40,766 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725020
2022-01-09T11:43:40,766 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20472.5703125|#Level:Host|#hostname:pressler-dell,timestamp:1641725020
2022-01-09T11:43:40,766 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8426.89453125|#Level:Host|#hostname:pressler-dell,timestamp:1641725020
2022-01-09T11:43:40,766 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:35.9|#Level:Host|#hostname:pressler-dell,timestamp:1641725020
2022-01-09T11:44:40,765 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725080
2022-01-09T11:44:40,766 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.28466415405273|#Level:Host|#hostname:pressler-dell,timestamp:1641725080
2022-01-09T11:44:40,766 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9690742492676|#Level:Host|#hostname:pressler-dell,timestamp:1641725080
2022-01-09T11:44:40,768 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725080
2022-01-09T11:44:40,768 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20518.1171875|#Level:Host|#hostname:pressler-dell,timestamp:1641725080
2022-01-09T11:44:40,769 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8397.984375|#Level:Host|#hostname:pressler-dell,timestamp:1641725080
2022-01-09T11:44:40,769 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:35.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725080
2022-01-09T11:45:40,803 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725140
2022-01-09T11:45:40,807 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:76.28463363647461|#Level:Host|#hostname:pressler-dell,timestamp:1641725140
2022-01-09T11:45:40,807 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:421.9691047668457|#Level:Host|#hostname:pressler-dell,timestamp:1641725140
2022-01-09T11:45:40,811 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725140
2022-01-09T11:45:40,812 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:20493.375|#Level:Host|#hostname:pressler-dell,timestamp:1641725140
2022-01-09T11:45:40,817 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8394.3515625|#Level:Host|#hostname:pressler-dell,timestamp:1641725140
2022-01-09T11:45:40,822 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:35.8|#Level:Host|#hostname:pressler-dell,timestamp:1641725140
2022-01-09T11:46:40,747 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725200
2022-01-09T11:46:40,747 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:76.28460311889648|#Level:Host|#hostname:pressler-dell,timestamp:1641725200
2022-01-09T11:46:40,747 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:421.9691352844238|#Level:Host|#hostname:pressler-dell,timestamp:1641725200
2022-01-09T11:46:40,748 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725200
2022-01-09T11:46:40,749 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:20308.85546875|#Level:Host|#hostname:pressler-dell,timestamp:1641725200
2022-01-09T11:46:40,751 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8539.35546875|#Level:Host|#hostname:pressler-dell,timestamp:1641725200
2022-01-09T11:46:40,751 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:36.4|#Level:Host|#hostname:pressler-dell,timestamp:1641725200
2022-01-09T11:47:40,762 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725260
2022-01-09T11:47:40,762 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:76.2841567993164|#Level:Host|#hostname:pressler-dell,timestamp:1641725260
2022-01-09T11:47:40,762 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:421.9695816040039|#Level:Host|#hostname:pressler-dell,timestamp:1641725260
2022-01-09T11:47:40,763 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725260
2022-01-09T11:47:40,763 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:18248.28515625|#Level:Host|#hostname:pressler-dell,timestamp:1641725260
2022-01-09T11:47:40,763 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:10665.46875|#Level:Host|#hostname:pressler-dell,timestamp:1641725260
2022-01-09T11:47:40,763 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:42.8|#Level:Host|#hostname:pressler-dell,timestamp:1641725260
2022-01-09T11:48:40,751 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725320
2022-01-09T11:48:40,752 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:76.28444290161133|#Level:Host|#hostname:pressler-dell,timestamp:1641725320
2022-01-09T11:48:40,753 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:421.969295501709|#Level:Host|#hostname:pressler-dell,timestamp:1641725320
2022-01-09T11:48:40,753 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725320
2022-01-09T11:48:40,753 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:18255.0546875|#Level:Host|#hostname:pressler-dell,timestamp:1641725320
2022-01-09T11:48:40,754 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:10649.0859375|#Level:Host|#hostname:pressler-dell,timestamp:1641725320
2022-01-09T11:48:40,754 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:42.8|#Level:Host|#hostname:pressler-dell,timestamp:1641725320
2022-01-09T11:49:40,821 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725380
2022-01-09T11:49:40,821 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:76.28413391113281|#Level:Host|#hostname:pressler-dell,timestamp:1641725380
2022-01-09T11:49:40,822 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:421.9696044921875|#Level:Host|#hostname:pressler-dell,timestamp:1641725380
2022-01-09T11:49:40,823 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725380
2022-01-09T11:49:40,826 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:18151.21484375|#Level:Host|#hostname:pressler-dell,timestamp:1641725380
2022-01-09T11:49:40,827 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:10691.33984375|#Level:Host|#hostname:pressler-dell,timestamp:1641725380
2022-01-09T11:49:40,827 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.1|#Level:Host|#hostname:pressler-dell,timestamp:1641725380
2022-01-09T11:50:40,783 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725440
2022-01-09T11:50:40,785 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:76.28394317626953|#Level:Host|#hostname:pressler-dell,timestamp:1641725440
2022-01-09T11:50:40,785 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:421.9697952270508|#Level:Host|#hostname:pressler-dell,timestamp:1641725440
2022-01-09T11:50:40,786 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725440
2022-01-09T11:50:40,788 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:18015.16015625|#Level:Host|#hostname:pressler-dell,timestamp:1641725440
2022-01-09T11:50:40,789 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:10777.22265625|#Level:Host|#hostname:pressler-dell,timestamp:1641725440
2022-01-09T11:50:40,790 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.6|#Level:Host|#hostname:pressler-dell,timestamp:1641725440
2022-01-09T11:51:40,758 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725500
2022-01-09T11:51:40,758 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:76.28379821777344|#Level:Host|#hostname:pressler-dell,timestamp:1641725500
2022-01-09T11:51:40,758 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:421.9699401855469|#Level:Host|#hostname:pressler-dell,timestamp:1641725500
2022-01-09T11:51:40,758 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725500
2022-01-09T11:51:40,758 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:18264.1015625|#Level:Host|#hostname:pressler-dell,timestamp:1641725500
2022-01-09T11:51:40,759 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:10614.7734375|#Level:Host|#hostname:pressler-dell,timestamp:1641725500
2022-01-09T11:51:40,759 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:42.8|#Level:Host|#hostname:pressler-dell,timestamp:1641725500
2022-01-09T11:52:40,754 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725560
2022-01-09T11:52:40,756 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:76.28422546386719|#Level:Host|#hostname:pressler-dell,timestamp:1641725560
2022-01-09T11:52:40,756 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:421.9695129394531|#Level:Host|#hostname:pressler-dell,timestamp:1641725560
2022-01-09T11:52:40,757 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725560
2022-01-09T11:52:40,757 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:20267.08203125|#Level:Host|#hostname:pressler-dell,timestamp:1641725560
2022-01-09T11:52:40,757 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8569.35546875|#Level:Host|#hostname:pressler-dell,timestamp:1641725560
2022-01-09T11:52:40,758 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:36.5|#Level:Host|#hostname:pressler-dell,timestamp:1641725560
2022-01-09T11:53:01,771 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T11:53:01,771 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T11:53:01,915 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T11:53:01,915 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T11:53:01,922 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T11:53:01,922 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T11:53:01,950 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T11:53:01,950 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T11:53:02,659 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T11:53:02,659 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T11:53:02,661 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T11:53:02,661 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T11:53:02,661 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T11:53:02,661 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T11:53:02,661 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T11:53:02,661 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T11:53:02,669 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T11:53:02,669 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T11:53:02,674 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T11:53:02,674 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T11:53:03,599 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T11:53:03,600 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]60457
2022-01-09T11:53:03,602 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T11:53:03,602 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T11:53:03,601 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T11:53:03,605 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T11:53:03,621 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T11:53:03,621 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T11:53:03,736 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T11:53:03,739 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641725583739
2022-01-09T11:53:03,739 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641725583739
2022-01-09T11:53:03,776 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T11:53:04,017 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T11:53:04,017 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T11:53:04,020 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T11:53:04,020 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T11:53:04,022 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T11:53:04,022 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T11:53:04,032 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T11:53:04,032 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T11:53:04,044 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T11:53:04,044 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T11:53:04,063 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T11:53:04,063 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T11:53:04,079 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T11:53:04,079 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T11:53:04,079 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T11:53:04,079 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T11:53:04,087 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T11:53:04,087 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T11:53:04,088 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T11:53:04,088 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T11:53:04,089 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T11:53:04,089 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T11:53:04,383 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T11:53:04,383 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T11:53:04,498 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725584
2022-01-09T11:53:04,501 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.28410339355469|#Level:Host|#hostname:pressler-dell,timestamp:1641725584
2022-01-09T11:53:04,508 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9696350097656|#Level:Host|#hostname:pressler-dell,timestamp:1641725584
2022-01-09T11:53:04,512 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725584
2022-01-09T11:53:04,514 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:22330.90625|#Level:Host|#hostname:pressler-dell,timestamp:1641725584
2022-01-09T11:53:04,517 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:6456.5625|#Level:Host|#hostname:pressler-dell,timestamp:1641725584
2022-01-09T11:53:04,521 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:30.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725584
2022-01-09T11:53:04,660 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 874
2022-01-09T11:53:04,660 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 874
2022-01-09T11:53:04,662 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T11:53:04,662 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T11:53:04,663 [INFO ] W-9000-scalenet_1.0 TS_METRICS - W-9000-scalenet_1.0.ms:1996|#Level:Host|#hostname:pressler-dell,timestamp:1641725584
2022-01-09T11:53:04,665 [INFO ] W-9000-scalenet_1.0 TS_METRICS - WorkerThreadTime.ms:52|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T11:53:05,131 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T11:53:05,132 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]60473
2022-01-09T11:53:05,133 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T11:53:05,133 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T11:53:05,133 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T11:53:05,133 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T11:53:05,133 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T11:53:05,133 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T11:53:05,136 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641725585136
2022-01-09T11:53:05,136 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T11:53:05,136 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641725585136
2022-01-09T11:53:05,169 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T11:53:09,017 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T11:53:09,023 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T11:53:09,056 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T11:53:09,056 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T11:53:09,636 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding NMS... 
2022-01-09T11:53:09,637 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T11:53:09,638 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T11:53:09,638 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 224 layers, 7056607 parameters, 7056607 gradients, 16.3 GFLOPS
2022-01-09T11:53:09,639 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T11:53:09,640 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4471
2022-01-09T11:53:09,640 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4471
2022-01-09T11:53:09,641 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T11:53:09,641 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T11:53:09,641 [INFO ] W-9001-yolov5_0.1 TS_METRICS - W-9001-yolov5_0.1.ms:5607|#Level:Host|#hostname:pressler-dell,timestamp:1641725589
2022-01-09T11:53:09,641 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:34|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T11:53:09,639 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model file /tmp/models/eec387e30ae74b36a1943cf46885a098/yolov5s.pt loaded successfully
2022-01-09T11:53:10,235 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641725590235
2022-01-09T11:53:10,235 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641725590235
2022-01-09T11:53:10,246 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641725590
2022-01-09T11:53:10,406 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Invoking custom service failed.
2022-01-09T11:53:10,407 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 162
2022-01-09T11:53:10,407 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 162
2022-01-09T11:53:10,407 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T11:53:10,416 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-01-09T11:53:10,417 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-01-09T11:53:10,418 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/eec387e30ae74b36a1943cf46885a098/torchserve_handler.py", line 108, in handle
2022-01-09T11:53:10,418 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     predictions = self.model(data_preprocess)
2022-01-09T11:53:10,418 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/home/pressler/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
2022-01-09T11:53:10,433 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     return forward_call(*input, **kwargs)
2022-01-09T11:53:10,435 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/eec387e30ae74b36a1943cf46885a098/models/common.py", line 257, in forward
2022-01-09T11:53:10,436 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     y = non_max_suppression(
2022-01-09T11:53:10,436 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/eec387e30ae74b36a1943cf46885a098/utils/general.py", line 487, in non_max_suppression
2022-01-09T11:53:10,436 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     nc = prediction.shape[2] - 5  # number of classes
2022-01-09T11:53:10,455 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - IndexError: tuple index out of range
2022-01-09T11:53:10,454 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:53902 "POST /predictions/yolov5 HTTP/1.1" 503 339
2022-01-09T11:53:10,461 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T11:53:10,468 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 193701, Inference time ns: 232780231
2022-01-09T11:53:10,468 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 193701, Inference time ns: 232780231
2022-01-09T11:53:10,468 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:71|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T11:54:04,468 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725644
2022-01-09T11:54:04,469 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.28414916992188|#Level:Host|#hostname:pressler-dell,timestamp:1641725644
2022-01-09T11:54:04,470 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.96958923339844|#Level:Host|#hostname:pressler-dell,timestamp:1641725644
2022-01-09T11:54:04,476 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725644
2022-01-09T11:54:04,476 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20198.4453125|#Level:Host|#hostname:pressler-dell,timestamp:1641725644
2022-01-09T11:54:04,476 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8551.93359375|#Level:Host|#hostname:pressler-dell,timestamp:1641725644
2022-01-09T11:54:04,476 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:36.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725644
2022-01-09T11:55:04,568 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725704
2022-01-09T11:55:04,573 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.28147506713867|#Level:Host|#hostname:pressler-dell,timestamp:1641725704
2022-01-09T11:55:04,576 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.97226333618164|#Level:Host|#hostname:pressler-dell,timestamp:1641725704
2022-01-09T11:55:04,579 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725704
2022-01-09T11:55:04,586 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19612.2734375|#Level:Host|#hostname:pressler-dell,timestamp:1641725704
2022-01-09T11:55:04,589 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8994.14453125|#Level:Host|#hostname:pressler-dell,timestamp:1641725704
2022-01-09T11:55:04,592 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:38.6|#Level:Host|#hostname:pressler-dell,timestamp:1641725704
2022-01-09T11:56:04,427 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725764
2022-01-09T11:56:04,428 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:76.31451797485352|#Level:Host|#hostname:pressler-dell,timestamp:1641725764
2022-01-09T11:56:04,428 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:421.9392204284668|#Level:Host|#hostname:pressler-dell,timestamp:1641725764
2022-01-09T11:56:04,428 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725764
2022-01-09T11:56:04,428 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:18163.83203125|#Level:Host|#hostname:pressler-dell,timestamp:1641725764
2022-01-09T11:56:04,429 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:10645.98828125|#Level:Host|#hostname:pressler-dell,timestamp:1641725764
2022-01-09T11:56:04,429 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.1|#Level:Host|#hostname:pressler-dell,timestamp:1641725764
2022-01-09T11:57:04,439 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725824
2022-01-09T11:57:04,441 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.31200408935547|#Level:Host|#hostname:pressler-dell,timestamp:1641725824
2022-01-09T11:57:04,453 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.94173431396484|#Level:Host|#hostname:pressler-dell,timestamp:1641725824
2022-01-09T11:57:04,455 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725824
2022-01-09T11:57:04,456 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17817.7421875|#Level:Host|#hostname:pressler-dell,timestamp:1641725824
2022-01-09T11:57:04,457 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:10776.0078125|#Level:Host|#hostname:pressler-dell,timestamp:1641725824
2022-01-09T11:57:04,457 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:44.2|#Level:Host|#hostname:pressler-dell,timestamp:1641725824
2022-01-09T11:58:04,429 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725884
2022-01-09T11:58:04,429 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:76.30711364746094|#Level:Host|#hostname:pressler-dell,timestamp:1641725884
2022-01-09T11:58:04,430 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:421.9466247558594|#Level:Host|#hostname:pressler-dell,timestamp:1641725884
2022-01-09T11:58:04,430 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725884
2022-01-09T11:58:04,430 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:17900.98828125|#Level:Host|#hostname:pressler-dell,timestamp:1641725884
2022-01-09T11:58:04,430 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:10796.92578125|#Level:Host|#hostname:pressler-dell,timestamp:1641725884
2022-01-09T11:58:04,431 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.9|#Level:Host|#hostname:pressler-dell,timestamp:1641725884
2022-01-09T11:59:04,431 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641725944
2022-01-09T11:59:04,431 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.3070297241211|#Level:Host|#hostname:pressler-dell,timestamp:1641725944
2022-01-09T11:59:04,431 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9467086791992|#Level:Host|#hostname:pressler-dell,timestamp:1641725944
2022-01-09T11:59:04,432 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725944
2022-01-09T11:59:04,432 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17976.4921875|#Level:Host|#hostname:pressler-dell,timestamp:1641725944
2022-01-09T11:59:04,432 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:10787.90625|#Level:Host|#hostname:pressler-dell,timestamp:1641725944
2022-01-09T11:59:04,432 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:43.7|#Level:Host|#hostname:pressler-dell,timestamp:1641725944
2022-01-09T12:00:04,564 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:pressler-dell,timestamp:1641726004
2022-01-09T12:00:04,565 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.31815338134766|#Level:Host|#hostname:pressler-dell,timestamp:1641726004
2022-01-09T12:00:04,567 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.93558502197266|#Level:Host|#hostname:pressler-dell,timestamp:1641726004
2022-01-09T12:00:04,568 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641726004
2022-01-09T12:00:04,570 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19487.69140625|#Level:Host|#hostname:pressler-dell,timestamp:1641726004
2022-01-09T12:00:04,571 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8942.796875|#Level:Host|#hostname:pressler-dell,timestamp:1641726004
2022-01-09T12:00:04,572 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:39.0|#Level:Host|#hostname:pressler-dell,timestamp:1641726004
2022-01-09T12:01:16,461 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:01:16,461 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:01:16,607 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:01:16,607 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:01:16,613 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:01:16,613 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:01:16,645 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:01:16,645 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:01:17,437 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:01:17,437 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:01:17,438 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:01:17,438 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:01:17,440 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:01:17,440 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:01:17,442 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:01:17,442 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:01:17,456 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:01:17,456 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:01:17,460 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:01:17,460 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:01:18,603 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T12:01:18,604 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]63012
2022-01-09T12:01:18,604 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:01:18,604 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:01:18,605 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:01:18,605 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:01:18,627 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:01:18,627 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:01:18,725 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T12:01:18,730 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726078730
2022-01-09T12:01:18,730 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726078730
2022-01-09T12:01:18,826 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T12:01:19,047 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:01:19,047 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:01:19,050 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:01:19,050 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:01:19,058 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:01:19,058 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:01:19,059 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:01:19,059 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:01:19,062 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:01:19,062 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:01:19,077 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:01:19,077 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:01:19,096 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:01:19,096 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:01:19,098 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:01:19,098 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:01:19,114 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:01:19,114 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:01:19,115 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:01:19,115 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:01:19,116 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:01:19,116 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:01:19,423 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:01:19,423 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:01:19,491 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641726079
2022-01-09T12:01:19,502 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.31342697143555|#Level:Host|#hostname:pressler-dell,timestamp:1641726079
2022-01-09T12:01:19,504 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.94031143188477|#Level:Host|#hostname:pressler-dell,timestamp:1641726079
2022-01-09T12:01:19,506 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641726079
2022-01-09T12:01:19,507 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21829.26171875|#Level:Host|#hostname:pressler-dell,timestamp:1641726079
2022-01-09T12:01:19,513 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:6653.01953125|#Level:Host|#hostname:pressler-dell,timestamp:1641726079
2022-01-09T12:01:19,514 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:31.6|#Level:Host|#hostname:pressler-dell,timestamp:1641726079
2022-01-09T12:01:19,726 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 883
2022-01-09T12:01:19,726 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 883
2022-01-09T12:01:19,727 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:01:19,727 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:01:19,727 [INFO ] W-9000-scalenet_1.0 TS_METRICS - W-9000-scalenet_1.0.ms:2275|#Level:Host|#hostname:pressler-dell,timestamp:1641726079
2022-01-09T12:01:19,727 [INFO ] W-9000-scalenet_1.0 TS_METRICS - WorkerThreadTime.ms:114|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:01:20,111 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:01:20,112 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]63039
2022-01-09T12:01:20,112 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:01:20,112 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:01:20,113 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:01:20,112 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:01:20,113 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:01:20,113 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:01:20,114 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:01:20,115 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726080115
2022-01-09T12:01:20,115 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726080115
2022-01-09T12:01:20,156 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:01:25,885 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:01:25,886 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:01:25,921 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:01:25,921 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:01:26,427 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding NMS... 
2022-01-09T12:01:26,428 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:01:26,428 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:01:26,428 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 224 layers, 7056607 parameters, 7056607 gradients, 16.3 GFLOPS
2022-01-09T12:01:26,434 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:01:26,434 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model file /tmp/models/eab0c2989c7f4cb5bad1cd1670bf8cb8/yolov5s.pt loaded successfully
2022-01-09T12:01:26,438 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6282
2022-01-09T12:01:26,438 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6282
2022-01-09T12:01:26,440 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:01:26,440 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:01:26,440 [INFO ] W-9001-yolov5_0.1 TS_METRICS - W-9001-yolov5_0.1.ms:7379|#Level:Host|#hostname:pressler-dell,timestamp:1641726086
2022-01-09T12:01:26,441 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:44|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:01:26,441 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726086441
2022-01-09T12:01:26,441 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726086441
2022-01-09T12:01:26,447 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641726086
2022-01-09T12:01:26,609 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Invoking custom service failed.
2022-01-09T12:01:26,609 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:01:26,610 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 164
2022-01-09T12:01:26,610 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-01-09T12:01:26,610 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 164
2022-01-09T12:01:26,610 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-01-09T12:01:26,610 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/eab0c2989c7f4cb5bad1cd1670bf8cb8/torchserve_handler.py", line 108, in handle
2022-01-09T12:01:26,610 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     predictions = self.model(data_preprocess)
2022-01-09T12:01:26,611 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/home/pressler/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
2022-01-09T12:01:26,611 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     return forward_call(*input, **kwargs)
2022-01-09T12:01:26,612 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/eab0c2989c7f4cb5bad1cd1670bf8cb8/models/common.py", line 256, in forward
2022-01-09T12:01:26,612 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     y = self.model(x, augment, profile)[0]  # forward
2022-01-09T12:01:26,613 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/home/pressler/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
2022-01-09T12:01:26,613 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     return forward_call(*input, **kwargs)
2022-01-09T12:01:26,613 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/eab0c2989c7f4cb5bad1cd1670bf8cb8/models/yolo.py", line 134, in forward
2022-01-09T12:01:26,613 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     return self.forward_once(x, profile)
2022-01-09T12:01:26,613 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/eab0c2989c7f4cb5bad1cd1670bf8cb8/models/yolo.py", line 152, in forward_once
2022-01-09T12:01:26,614 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     x = m(x)  # run
2022-01-09T12:01:26,614 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/home/pressler/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
2022-01-09T12:01:26,616 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     return forward_call(*input, **kwargs)
2022-01-09T12:01:26,620 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/eab0c2989c7f4cb5bad1cd1670bf8cb8/models/common.py", line 176, in forward
2022-01-09T12:01:26,623 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     return non_max_suppression(
2022-01-09T12:01:26,628 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/eab0c2989c7f4cb5bad1cd1670bf8cb8/utils/general.py", line 487, in non_max_suppression
2022-01-09T12:01:26,624 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:54100 "POST /predictions/yolov5 HTTP/1.1" 503 4356
2022-01-09T12:01:26,631 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:01:26,632 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     prediction = prediction.pred
2022-01-09T12:01:26,637 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 3991018794, Inference time ns: 4186752768
2022-01-09T12:01:26,638 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - AttributeError: 'Tensor' object has no attribute 'pred'
2022-01-09T12:01:26,637 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 3991018794, Inference time ns: 4186752768
2022-01-09T12:01:26,641 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:36|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:02:19,688 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641726139
2022-01-09T12:02:19,692 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.286865234375|#Level:Host|#hostname:pressler-dell,timestamp:1641726139
2022-01-09T12:02:19,694 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9668731689453|#Level:Host|#hostname:pressler-dell,timestamp:1641726139
2022-01-09T12:02:19,700 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641726139
2022-01-09T12:02:19,702 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19510.8984375|#Level:Host|#hostname:pressler-dell,timestamp:1641726139
2022-01-09T12:02:19,712 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8932.95703125|#Level:Host|#hostname:pressler-dell,timestamp:1641726139
2022-01-09T12:02:19,714 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:38.9|#Level:Host|#hostname:pressler-dell,timestamp:1641726139
2022-01-09T12:02:21,334 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-01-09T12:02:21,334 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-01-09T12:02:21,339 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-01-09T12:02:21,339 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-01-09T12:02:21,341 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2022-01-09T12:02:21,341 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2022-01-09T12:02:31,748 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:02:31,748 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:02:31,843 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:02:31,843 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:02:31,849 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:02:31,849 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:02:31,883 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:02:31,883 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:02:32,518 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:02:32,518 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:02:32,519 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:02:32,519 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:02:32,519 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:02:32,519 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:02:32,519 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:02:32,519 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:02:32,529 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:02:32,529 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:02:32,543 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:02:32,543 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:02:33,804 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T12:02:33,820 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]63475
2022-01-09T12:02:33,822 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:02:33,822 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:02:33,831 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:02:33,833 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:02:33,868 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:02:33,868 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:02:33,979 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T12:02:33,987 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726153987
2022-01-09T12:02:33,987 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726153987
2022-01-09T12:02:34,050 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T12:02:34,306 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:02:34,306 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:02:34,312 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:02:34,312 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:02:34,314 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:02:34,314 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:02:34,315 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:02:34,315 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:02:34,330 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:02:34,330 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:02:34,330 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:02:34,330 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:02:34,352 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:02:34,352 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:02:34,363 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:02:34,363 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:02:34,378 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:02:34,378 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:02:34,378 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:02:34,378 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:02:34,379 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:02:34,379 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:02:34,696 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:02:34,696 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:02:34,787 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641726154
2022-01-09T12:02:34,789 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.28684616088867|#Level:Host|#hostname:pressler-dell,timestamp:1641726154
2022-01-09T12:02:34,791 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.96689224243164|#Level:Host|#hostname:pressler-dell,timestamp:1641726154
2022-01-09T12:02:34,793 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641726154
2022-01-09T12:02:34,795 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21557.01171875|#Level:Host|#hostname:pressler-dell,timestamp:1641726154
2022-01-09T12:02:34,797 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:6901.24609375|#Level:Host|#hostname:pressler-dell,timestamp:1641726154
2022-01-09T12:02:34,799 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:32.5|#Level:Host|#hostname:pressler-dell,timestamp:1641726154
2022-01-09T12:02:35,073 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1010
2022-01-09T12:02:35,073 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1010
2022-01-09T12:02:35,074 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:02:35,074 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:02:35,074 [INFO ] W-9000-scalenet_1.0 TS_METRICS - W-9000-scalenet_1.0.ms:2547|#Level:Host|#hostname:pressler-dell,timestamp:1641726155
2022-01-09T12:02:35,074 [INFO ] W-9000-scalenet_1.0 TS_METRICS - WorkerThreadTime.ms:77|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:02:35,334 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:02:35,335 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]63492
2022-01-09T12:02:35,335 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:02:35,335 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:02:35,335 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:02:35,335 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:02:35,335 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:02:35,335 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:02:35,337 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726155337
2022-01-09T12:02:35,337 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726155337
2022-01-09T12:02:35,342 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:02:35,366 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:02:40,166 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:02:40,167 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:02:40,195 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:02:40,196 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:02:40,708 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding NMS... 
2022-01-09T12:02:40,708 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:02:40,708 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:02:40,708 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 224 layers, 7056607 parameters, 7056607 gradients, 16.3 GFLOPS
2022-01-09T12:02:40,712 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:02:40,712 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model file /tmp/models/9e2336e9a1404de28c15f5d19a56460c/yolov5s.pt loaded successfully
2022-01-09T12:02:40,717 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5352
2022-01-09T12:02:40,717 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5352
2022-01-09T12:02:40,717 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:02:40,717 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:02:40,718 [INFO ] W-9001-yolov5_0.1 TS_METRICS - W-9001-yolov5_0.1.ms:6401|#Level:Host|#hostname:pressler-dell,timestamp:1641726160
2022-01-09T12:02:40,719 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:30|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:02:40,719 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726160719
2022-01-09T12:02:40,719 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726160719
2022-01-09T12:02:40,723 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641726160
2022-01-09T12:02:40,852 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - tensor([[[4.88627e+00, 4.70502e+00, 8.60011e+00,  ..., 1.13483e-03, 1.03445e-03, 1.57132e-03],
2022-01-09T12:02:40,853 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 131
2022-01-09T12:02:40,854 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -          [1.28531e+01, 3.73211e+00, 2.46558e+01,  ..., 1.17892e-03, 1.10640e-03, 1.36077e-03],
2022-01-09T12:02:40,855 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -          [1.87653e+01, 4.44659e+00, 3.28578e+01,  ..., 7.91619e-04, 7.89796e-04, 1.22634e-03],
2022-01-09T12:02:40,853 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 131
2022-01-09T12:02:40,857 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -          ...,
2022-01-09T12:02:40,859 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -          [5.60306e+02, 3.70196e+02, 2.41535e+02,  ..., 2.52675e-03, 1.15087e-03, 1.81743e-03],
2022-01-09T12:02:40,867 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -          [5.80544e+02, 3.61531e+02, 1.48600e+02,  ..., 2.63996e-03, 1.42779e-03, 3.01391e-03],
2022-01-09T12:02:40,868 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -          [6.10032e+02, 3.68001e+02, 1.48255e+02,  ..., 2.87836e-03, 1.18944e-03, 2.14180e-03]]], device='cuda:0')
2022-01-09T12:02:40,869 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - tensor([[4.39533e+02, 7.98804e+01, 5.28515e+02, 2.65118e+02, 9.11163e-01, 0.00000e+00],
2022-01-09T12:02:40,873 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [1.69342e+02, 1.00993e+02, 2.38483e+02, 3.07660e+02, 9.02362e-01, 0.00000e+00],
2022-01-09T12:02:40,872 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:54136 "POST /predictions/yolov5 HTTP/1.1" 503 4057
2022-01-09T12:02:40,873 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [3.05105e+02, 1.08319e+02, 3.40981e+02, 1.66041e+02, 8.17463e-01, 5.60000e+01],
2022-01-09T12:02:40,873 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:02:40,874 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [4.29610e+02, 6.87754e+01, 4.86586e+02, 1.09622e+02, 6.95550e-01, 6.20000e+01],
2022-01-09T12:02:40,874 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [3.99402e+02, 1.00125e+02, 4.43999e+02, 1.82415e+02, 6.49064e-01, 5.60000e+01],
2022-01-09T12:02:40,874 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [1.68738e+02, 9.33274e+01, 1.97449e+02, 1.19139e+02, 4.56054e-01, 6.20000e+01],
2022-01-09T12:02:40,875 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [5.09438e+02, 1.39906e+02, 5.64642e+02, 1.97552e+02, 4.12818e-01, 5.60000e+01],
2022-01-09T12:02:40,879 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 3767476840, Inference time ns: 3927008663
2022-01-09T12:02:40,879 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 3767476840, Inference time ns: 3927008663
2022-01-09T12:02:40,880 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:30|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:02:40,876 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [3.31472e+00, 7.29199e+01, 3.87955e+01, 9.69154e+01, 4.10264e-01, 6.30000e+01],
2022-01-09T12:02:40,903 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [5.47509e+02, 1.14463e+02, 5.83599e+02, 1.38855e+02, 4.05233e-01, 5.60000e+01],
2022-01-09T12:02:40,908 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [5.34132e+02, 1.37859e+02, 5.75131e+02, 1.93348e+02, 3.05852e-01, 5.60000e+01],
2022-01-09T12:02:40,914 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [2.20178e+02, 1.07753e+02, 2.53037e+02, 1.23777e+02, 2.80224e-01, 5.60000e+01],
2022-01-09T12:02:40,917 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [3.64785e+00, 7.31410e+01, 3.90485e+01, 9.67624e+01, 2.66547e-01, 6.20000e+01],
2022-01-09T12:02:40,918 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [1.42143e+02, 9.78887e+01, 1.71741e+02, 1.33552e+02, 2.63227e-01, 6.20000e+01]], device='cuda:0')
2022-01-09T12:02:40,919 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Invoking custom service failed.
2022-01-09T12:02:40,920 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:02:40,921 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-01-09T12:02:40,922 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-01-09T12:02:40,923 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/9e2336e9a1404de28c15f5d19a56460c/torchserve_handler.py", line 108, in handle
2022-01-09T12:02:40,924 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     predictions = self.model(data_preprocess)
2022-01-09T12:02:40,924 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/home/pressler/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
2022-01-09T12:02:40,925 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     return forward_call(*input, **kwargs)
2022-01-09T12:02:40,925 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/9e2336e9a1404de28c15f5d19a56460c/models/common.py", line 257, in forward
2022-01-09T12:02:40,925 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     y = non_max_suppression(
2022-01-09T12:02:40,926 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/9e2336e9a1404de28c15f5d19a56460c/utils/general.py", line 489, in non_max_suppression
2022-01-09T12:02:40,927 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     nc = prediction.shape[2] - 5  # number of classes
2022-01-09T12:02:40,927 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - IndexError: tuple index out of range
2022-01-09T12:03:35,733 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:03:35,733 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:03:35,848 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:03:35,848 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:03:35,854 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:03:35,854 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:03:35,876 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:03:35,876 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:03:36,525 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:03:36,525 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:03:36,526 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:03:36,526 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:03:36,526 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:03:36,526 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:03:36,526 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:03:36,526 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:03:36,535 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:03:36,535 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:03:36,540 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:03:36,540 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:03:37,367 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T12:03:37,368 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]63775
2022-01-09T12:03:37,368 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:03:37,368 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:03:37,369 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:03:37,369 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:03:37,389 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:03:37,389 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:03:37,484 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T12:03:37,488 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726217488
2022-01-09T12:03:37,488 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726217488
2022-01-09T12:03:37,526 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T12:03:49,164 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:03:49,164 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:03:49,275 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:03:49,275 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:03:49,282 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:03:49,282 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:03:49,314 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:03:49,314 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:03:49,912 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:03:49,912 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:03:49,913 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:03:49,913 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:03:49,914 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:03:49,914 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:03:49,914 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:03:49,914 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:03:49,922 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:03:49,922 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:03:49,936 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:03:49,936 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:03:50,900 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T12:03:50,901 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]63930
2022-01-09T12:03:50,902 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:03:50,903 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:03:50,903 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:03:50,903 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:03:50,924 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:03:50,924 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:03:51,038 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T12:03:51,047 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726231047
2022-01-09T12:03:51,047 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726231047
2022-01-09T12:03:51,123 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T12:03:51,634 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:03:51,634 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:03:51,637 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:03:51,637 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:03:51,665 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:03:51,665 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:03:51,669 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:03:51,669 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:03:51,682 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:03:51,682 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:03:51,686 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:03:51,686 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:03:51,751 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:03:51,751 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:03:51,755 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:03:51,755 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:03:51,776 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:03:51,776 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:03:51,779 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:03:51,779 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:03:51,781 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:03:51,781 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:03:52,136 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:03:52,136 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:03:52,238 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641726232
2022-01-09T12:03:52,240 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.28662490844727|#Level:Host|#hostname:pressler-dell,timestamp:1641726232
2022-01-09T12:03:52,242 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.96711349487305|#Level:Host|#hostname:pressler-dell,timestamp:1641726232
2022-01-09T12:03:52,250 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641726232
2022-01-09T12:03:52,250 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21606.8671875|#Level:Host|#hostname:pressler-dell,timestamp:1641726232
2022-01-09T12:03:52,250 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:6918.4453125|#Level:Host|#hostname:pressler-dell,timestamp:1641726232
2022-01-09T12:03:52,251 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:32.3|#Level:Host|#hostname:pressler-dell,timestamp:1641726232
2022-01-09T12:03:52,332 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1203
2022-01-09T12:03:52,332 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1203
2022-01-09T12:03:52,337 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:03:52,337 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:03:52,341 [INFO ] W-9000-scalenet_1.0 TS_METRICS - W-9000-scalenet_1.0.ms:2421|#Level:Host|#hostname:pressler-dell,timestamp:1641726232
2022-01-09T12:03:52,346 [INFO ] W-9000-scalenet_1.0 TS_METRICS - WorkerThreadTime.ms:96|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:03:52,801 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:03:52,802 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]63955
2022-01-09T12:03:52,802 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:03:52,802 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:03:52,802 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:03:52,802 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:03:52,802 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:03:52,802 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:03:52,804 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726232804
2022-01-09T12:03:52,804 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726232804
2022-01-09T12:03:52,804 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:03:52,833 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:03:58,130 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:03:58,133 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:03:58,152 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:03:58,152 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:03:58,650 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding NMS... 
2022-01-09T12:03:58,650 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:03:58,651 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:03:58,651 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 224 layers, 7056607 parameters, 7056607 gradients, 16.3 GFLOPS
2022-01-09T12:03:58,657 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5825
2022-01-09T12:03:58,657 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5825
2022-01-09T12:03:58,657 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:03:58,657 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:03:58,658 [INFO ] W-9001-yolov5_0.1 TS_METRICS - W-9001-yolov5_0.1.ms:6984|#Level:Host|#hostname:pressler-dell,timestamp:1641726238
2022-01-09T12:03:58,659 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:30|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:03:58,661 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726238661
2022-01-09T12:03:58,661 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726238661
2022-01-09T12:03:58,663 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:03:58,665 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model file /tmp/models/10f81c11b50f44998a54d40076a229ce/yolov5s.pt loaded successfully
2022-01-09T12:03:58,674 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641726238
2022-01-09T12:03:58,805 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 131
2022-01-09T12:03:58,804 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - torch.Size([1, 15120, 85])
2022-01-09T12:03:58,807 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - torch.Size([13, 6])
2022-01-09T12:03:58,805 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 131
2022-01-09T12:03:58,810 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Invoking custom service failed.
2022-01-09T12:03:58,810 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:03:58,810 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-01-09T12:03:58,810 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-01-09T12:03:58,811 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/10f81c11b50f44998a54d40076a229ce/torchserve_handler.py", line 108, in handle
2022-01-09T12:03:58,811 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     predictions = self.model(data_preprocess)
2022-01-09T12:03:58,823 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/home/pressler/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
2022-01-09T12:03:58,824 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     return forward_call(*input, **kwargs)
2022-01-09T12:03:58,824 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/10f81c11b50f44998a54d40076a229ce/models/common.py", line 257, in forward
2022-01-09T12:03:58,824 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     y = non_max_suppression(
2022-01-09T12:03:58,824 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/10f81c11b50f44998a54d40076a229ce/utils/general.py", line 489, in non_max_suppression
2022-01-09T12:03:58,824 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     nc = prediction.shape[2] - 5  # number of classes
2022-01-09T12:03:58,825 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - IndexError: tuple index out of range
2022-01-09T12:03:58,822 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:54152 "POST /predictions/yolov5 HTTP/1.1" 503 4079
2022-01-09T12:03:58,827 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:03:58,849 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 3770705944, Inference time ns: 3958689542
2022-01-09T12:03:58,849 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 3770705944, Inference time ns: 3958689542
2022-01-09T12:03:58,850 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:58|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:05:09,696 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:05:09,696 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:05:09,798 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:05:09,798 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:05:09,804 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:05:09,804 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:05:09,828 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:05:09,828 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:05:10,482 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:05:10,482 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:05:10,482 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:05:10,482 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:05:10,486 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:05:10,486 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:05:10,486 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:05:10,486 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:05:10,525 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:05:10,525 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:05:10,532 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:05:10,532 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:05:12,112 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T12:05:12,124 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]64371
2022-01-09T12:05:12,131 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:05:12,131 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:05:12,141 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:05:12,143 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:05:12,211 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:05:12,211 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:05:12,439 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T12:05:12,451 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726312451
2022-01-09T12:05:12,451 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726312451
2022-01-09T12:05:12,549 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T12:05:12,572 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:05:12,572 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:05:12,572 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:05:12,572 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:05:12,573 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:05:12,573 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:05:12,573 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:05:12,573 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:05:12,577 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:05:12,577 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:05:12,590 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:05:12,590 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:05:12,611 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:05:12,611 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:05:12,612 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:05:12,612 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:05:12,647 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:05:12,647 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:05:12,651 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:05:12,651 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:05:12,656 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:05:12,656 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:05:13,156 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:05:13,156 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:05:13,296 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641726313
2022-01-09T12:05:13,298 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.28651428222656|#Level:Host|#hostname:pressler-dell,timestamp:1641726313
2022-01-09T12:05:13,299 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.96722412109375|#Level:Host|#hostname:pressler-dell,timestamp:1641726313
2022-01-09T12:05:13,300 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641726313
2022-01-09T12:05:13,302 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21405.82421875|#Level:Host|#hostname:pressler-dell,timestamp:1641726313
2022-01-09T12:05:13,303 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:6999.07421875|#Level:Host|#hostname:pressler-dell,timestamp:1641726313
2022-01-09T12:05:13,304 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:32.9|#Level:Host|#hostname:pressler-dell,timestamp:1641726313
2022-01-09T12:05:13,564 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1002
2022-01-09T12:05:13,564 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1002
2022-01-09T12:05:13,564 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:05:13,564 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:05:13,564 [INFO ] W-9000-scalenet_1.0 TS_METRICS - W-9000-scalenet_1.0.ms:3041|#Level:Host|#hostname:pressler-dell,timestamp:1641726313
2022-01-09T12:05:13,565 [INFO ] W-9000-scalenet_1.0 TS_METRICS - WorkerThreadTime.ms:112|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:05:13,811 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:05:13,812 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]64398
2022-01-09T12:05:13,812 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:05:13,812 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:05:13,813 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:05:13,812 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:05:13,813 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:05:13,813 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:05:13,815 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726313815
2022-01-09T12:05:13,815 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726313815
2022-01-09T12:05:13,815 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:05:13,841 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:05:18,916 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:05:18,917 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:05:18,942 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:05:18,944 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:05:19,411 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding NMS... 
2022-01-09T12:05:19,412 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:05:19,413 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:05:19,414 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 224 layers, 7056607 parameters, 7056607 gradients, 16.3 GFLOPS
2022-01-09T12:05:19,415 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:05:19,416 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model file /tmp/models/6d2b807aaeee4df5b261298c03001f56/yolov5s.pt loaded successfully
2022-01-09T12:05:19,416 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5575
2022-01-09T12:05:19,416 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5575
2022-01-09T12:05:19,417 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:05:19,417 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:05:19,417 [INFO ] W-9001-yolov5_0.1 TS_METRICS - W-9001-yolov5_0.1.ms:6844|#Level:Host|#hostname:pressler-dell,timestamp:1641726319
2022-01-09T12:05:19,418 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:27|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:05:19,418 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726319418
2022-01-09T12:05:19,418 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726319418
2022-01-09T12:05:19,423 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641726319
2022-01-09T12:05:19,552 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 129
2022-01-09T12:05:19,550 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Invoking custom service failed.
2022-01-09T12:05:19,554 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:05:19,556 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-01-09T12:05:19,559 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-01-09T12:05:19,559 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/6d2b807aaeee4df5b261298c03001f56/torchserve_handler.py", line 108, in handle
2022-01-09T12:05:19,559 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     predictions = self.model(data_preprocess)
2022-01-09T12:05:19,552 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 129
2022-01-09T12:05:19,560 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/home/pressler/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
2022-01-09T12:05:19,567 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     return forward_call(*input, **kwargs)
2022-01-09T12:05:19,568 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/6d2b807aaeee4df5b261298c03001f56/models/common.py", line 265, in forward
2022-01-09T12:05:19,569 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     scale_coords(shape1, y[i][:, :4], shape0[i])
2022-01-09T12:05:19,570 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - IndexError: too many indices for tensor of dimension 1
2022-01-09T12:05:19,573 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:54172 "POST /predictions/yolov5 HTTP/1.1" 503 4758
2022-01-09T12:05:19,575 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:05:19,577 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 4458988704, Inference time ns: 4618512332
2022-01-09T12:05:19,577 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 4458988704, Inference time ns: 4618512332
2022-01-09T12:05:19,579 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:32|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:06:13,167 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641726373
2022-01-09T12:06:13,168 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.28646469116211|#Level:Host|#hostname:pressler-dell,timestamp:1641726373
2022-01-09T12:06:13,169 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9672737121582|#Level:Host|#hostname:pressler-dell,timestamp:1641726373
2022-01-09T12:06:13,169 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641726373
2022-01-09T12:06:13,169 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19598.8828125|#Level:Host|#hostname:pressler-dell,timestamp:1641726373
2022-01-09T12:06:13,169 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8972.5703125|#Level:Host|#hostname:pressler-dell,timestamp:1641726373
2022-01-09T12:06:13,169 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:38.6|#Level:Host|#hostname:pressler-dell,timestamp:1641726373
2022-01-09T12:11:54,875 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:11:54,875 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:11:54,968 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:11:54,968 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:11:54,975 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:11:54,975 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:11:55,002 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:11:55,002 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:11:55,713 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:11:55,713 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:11:55,714 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:11:55,714 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:11:55,715 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:11:55,715 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:11:55,716 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:11:55,716 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:11:55,744 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:11:55,744 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:11:55,762 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:11:55,762 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:11:57,009 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T12:11:57,010 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]66358
2022-01-09T12:11:57,012 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:11:57,012 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:11:57,012 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:11:57,018 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:11:57,036 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:11:57,036 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:11:57,107 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T12:11:57,111 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726717111
2022-01-09T12:11:57,111 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726717111
2022-01-09T12:11:57,167 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T12:11:57,351 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:11:57,351 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:11:57,352 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:11:57,352 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:11:57,352 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:11:57,352 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:11:57,353 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:11:57,353 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:11:57,356 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:11:57,356 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:11:57,367 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:11:57,367 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:11:57,383 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:11:57,383 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:11:57,384 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:11:57,384 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:11:57,407 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:11:57,407 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:11:57,407 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:11:57,407 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:11:57,409 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:11:57,409 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:11:57,672 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:11:57,672 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:11:57,760 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641726717
2022-01-09T12:11:57,761 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27210235595703|#Level:Host|#hostname:pressler-dell,timestamp:1641726717
2022-01-09T12:11:57,772 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9816360473633|#Level:Host|#hostname:pressler-dell,timestamp:1641726717
2022-01-09T12:11:57,777 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641726717
2022-01-09T12:11:57,779 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19431.95703125|#Level:Host|#hostname:pressler-dell,timestamp:1641726717
2022-01-09T12:11:57,781 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8981.875|#Level:Host|#hostname:pressler-dell,timestamp:1641726717
2022-01-09T12:11:57,783 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:39.1|#Level:Host|#hostname:pressler-dell,timestamp:1641726717
2022-01-09T12:11:57,956 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 781
2022-01-09T12:11:57,956 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 781
2022-01-09T12:11:57,956 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:11:57,956 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:11:57,956 [INFO ] W-9000-scalenet_1.0 TS_METRICS - W-9000-scalenet_1.0.ms:2228|#Level:Host|#hostname:pressler-dell,timestamp:1641726717
2022-01-09T12:11:57,957 [INFO ] W-9000-scalenet_1.0 TS_METRICS - WorkerThreadTime.ms:65|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:11:58,236 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:11:58,237 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]66382
2022-01-09T12:11:58,237 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:11:58,238 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:11:58,238 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:11:58,238 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:11:58,238 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:11:58,238 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:11:58,240 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726718240
2022-01-09T12:11:58,240 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:11:58,240 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726718240
2022-01-09T12:11:58,268 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:12:03,399 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:12:03,400 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:12:03,422 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:12:03,423 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:12:03,427 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:12:03,427 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:12:03,432 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:12:03,432 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:12:03,429 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend worker process died.
2022-01-09T12:12:03,438 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:12:03,440 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-01-09T12:12:03,443 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     worker.run_server()
2022-01-09T12:12:03,447 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-01-09T12:12:03,450 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-09T12:12:03,454 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-01-09T12:12:03,463 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-09T12:12:03,469 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-01-09T12:12:03,473 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-09T12:12:03,479 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-01-09T12:12:03,485 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-01-09T12:12:03,492 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/7e9ca4d84fc24b7d99d0de5466835660/torchserve_handler.py", line 51, in initialize
2022-01-09T12:12:03,493 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.model = attempt_load(model_pt_path, map_location=self.device).autoshape([0])
2022-01-09T12:12:03,498 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - TypeError: autoshape() takes 1 positional argument but 2 were given
2022-01-09T12:12:03,433 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:12:03,433 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:12:03,543 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:12:03,543 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:12:03,544 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:12:03,544 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:12:03,546 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:12:03,546 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:12:03,548 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:12:03,548 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:12:03,553 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-09T12:12:03,553 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-09T12:12:03,818 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:12:03,818 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:12:03,822 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:12:03,822 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:12:04,555 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:12:04,555 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:12:05,980 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:12:05,982 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]66447
2022-01-09T12:12:05,983 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:12:05,983 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:12:05,983 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:12:05,983 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:12:05,983 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:12:05,985 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:12:05,996 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726725996
2022-01-09T12:12:05,996 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:12:05,996 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726725996
2022-01-09T12:12:06,037 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:12:12,100 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:12:12,101 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:12:12,132 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:12:12,132 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:12:12,137 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend worker process died.
2022-01-09T12:12:12,138 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:12:12,138 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-01-09T12:12:12,139 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     worker.run_server()
2022-01-09T12:12:12,139 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-01-09T12:12:12,140 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-09T12:12:12,140 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-01-09T12:12:12,140 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-09T12:12:12,140 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-01-09T12:12:12,140 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-09T12:12:12,141 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-01-09T12:12:12,141 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-01-09T12:12:12,141 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/7e9ca4d84fc24b7d99d0de5466835660/torchserve_handler.py", line 51, in initialize
2022-01-09T12:12:12,141 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.model = attempt_load(model_pt_path, map_location=self.device).autoshape([0])
2022-01-09T12:12:12,141 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - TypeError: autoshape() takes 1 positional argument but 2 were given
2022-01-09T12:12:12,142 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:12:12,142 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:12:12,143 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:12:12,143 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:12:12,144 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:12:12,144 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:12:12,145 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:12:12,145 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:12:12,145 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:12:12,145 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:12:12,146 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:12:12,146 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:12:12,146 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:12:12,146 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:12:12,146 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-09T12:12:12,146 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-09T12:12:12,353 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:12:12,353 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:12:12,353 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:12:12,353 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:12:13,147 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:12:13,147 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:12:14,729 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:12:14,731 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]66502
2022-01-09T12:12:14,733 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:12:14,732 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:12:14,733 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:12:14,733 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:12:14,733 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:12:14,735 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:12:14,743 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:12:14,747 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726734747
2022-01-09T12:12:14,747 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726734747
2022-01-09T12:12:14,801 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:12:21,031 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:12:21,032 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:12:21,055 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:12:21,056 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:12:21,059 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend worker process died.
2022-01-09T12:12:21,059 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:12:21,060 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-01-09T12:12:21,059 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:12:21,060 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     worker.run_server()
2022-01-09T12:12:21,060 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-01-09T12:12:21,061 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-09T12:12:21,062 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-01-09T12:12:21,059 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:12:21,063 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:12:21,063 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:12:21,064 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:12:21,064 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:12:21,065 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:12:21,065 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:12:21,065 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:12:21,065 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:12:21,062 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-09T12:12:21,066 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:12:21,066 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:12:21,066 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:12:21,066 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-01-09T12:12:21,066 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:12:21,066 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-01-09T12:12:21,066 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-09T12:12:21,066 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-01-09T12:12:21,066 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:12:21,066 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:12:21,321 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:12:21,321 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:12:23,067 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:12:23,067 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:12:24,310 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:12:24,311 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]66558
2022-01-09T12:12:24,311 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:12:24,312 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:12:24,312 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:12:24,312 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:12:24,312 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:12:24,312 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:12:24,315 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:12:24,316 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726744316
2022-01-09T12:12:24,316 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726744316
2022-01-09T12:12:24,367 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:12:25,180 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-01-09T12:12:25,180 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-01-09T12:12:25,181 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2022-01-09T12:12:25,181 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2022-01-09T12:12:25,183 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-01-09T12:12:25,183 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-01-09T12:12:45,194 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:12:45,194 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:12:45,304 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:12:45,304 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:12:45,311 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:12:45,311 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:12:45,352 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:12:45,352 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:12:45,919 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:12:45,919 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:12:45,922 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:12:45,922 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:12:45,923 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:12:45,923 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:12:45,923 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:12:45,923 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:12:45,931 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:12:45,931 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:12:45,933 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:12:45,933 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:12:46,738 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T12:12:46,739 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]66764
2022-01-09T12:12:46,739 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:12:46,740 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:12:46,740 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:12:46,743 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:12:46,752 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:12:46,752 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:12:46,834 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T12:12:46,838 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726766838
2022-01-09T12:12:46,838 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726766838
2022-01-09T12:12:46,881 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T12:12:47,157 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:12:47,157 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:12:47,157 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:12:47,157 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:12:47,157 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:12:47,157 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:12:47,157 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:12:47,157 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:12:47,159 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:12:47,159 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:12:47,160 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:12:47,160 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:12:47,211 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:12:47,211 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:12:47,212 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:12:47,212 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:12:47,215 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:12:47,215 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:12:47,216 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:12:47,216 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:12:47,219 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:12:47,219 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:12:47,434 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:12:47,434 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:12:47,506 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641726767
2022-01-09T12:12:47,507 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27205657958984|#Level:Host|#hostname:pressler-dell,timestamp:1641726767
2022-01-09T12:12:47,508 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.98168182373047|#Level:Host|#hostname:pressler-dell,timestamp:1641726767
2022-01-09T12:12:47,509 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641726767
2022-01-09T12:12:47,509 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19453.734375|#Level:Host|#hostname:pressler-dell,timestamp:1641726767
2022-01-09T12:12:47,510 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:9104.203125|#Level:Host|#hostname:pressler-dell,timestamp:1641726767
2022-01-09T12:12:47,510 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:39.1|#Level:Host|#hostname:pressler-dell,timestamp:1641726767
2022-01-09T12:12:47,590 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 696
2022-01-09T12:12:47,590 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 696
2022-01-09T12:12:47,590 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:12:47,590 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:12:47,590 [INFO ] W-9000-scalenet_1.0 TS_METRICS - W-9000-scalenet_1.0.ms:1661|#Level:Host|#hostname:pressler-dell,timestamp:1641726767
2022-01-09T12:12:47,591 [INFO ] W-9000-scalenet_1.0 TS_METRICS - WorkerThreadTime.ms:57|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:12:47,969 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:12:47,972 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]66788
2022-01-09T12:12:47,973 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:12:47,973 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:12:47,973 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:12:47,974 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:12:47,974 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:12:47,975 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:12:47,977 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726767977
2022-01-09T12:12:47,977 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:12:47,977 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726767977
2022-01-09T12:12:48,004 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:12:52,966 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:12:52,970 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:12:52,989 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:12:52,989 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:12:52,992 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend worker process died.
2022-01-09T12:12:52,993 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:12:52,993 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:12:52,993 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-01-09T12:12:52,993 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     worker.run_server()
2022-01-09T12:12:52,993 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:12:52,994 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-01-09T12:12:52,995 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-09T12:12:52,996 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:12:52,996 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:12:53,001 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-01-09T12:12:53,002 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-09T12:12:53,003 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-01-09T12:12:53,003 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-09T12:12:53,011 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-01-09T12:12:53,020 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-01-09T12:12:53,022 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/113541f89032406b85f32dfd7eafccd2/torchserve_handler.py", line 51, in initialize
2022-01-09T12:12:53,025 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.model = attempt_load(model_pt_path, map_location=self.device).autoshape(classes=[0])
2022-01-09T12:12:53,026 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - TypeError: autoshape() got an unexpected keyword argument 'classes'
2022-01-09T12:12:52,996 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:12:52,996 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:12:53,110 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:12:53,110 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:12:53,111 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:12:53,111 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:12:53,114 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:12:53,114 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:12:53,116 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:12:53,116 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:12:53,121 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-09T12:12:53,121 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-09T12:12:53,298 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:12:53,298 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:12:53,298 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:12:53,298 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:12:54,122 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:12:54,122 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:12:55,299 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:12:55,300 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]66855
2022-01-09T12:12:55,301 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:12:55,301 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:12:55,304 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:12:55,301 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:12:55,305 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:12:55,304 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:12:55,310 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726775309
2022-01-09T12:12:55,310 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726775309
2022-01-09T12:12:55,310 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:12:55,343 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:13:00,491 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:13:00,493 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:13:00,535 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:13:00,536 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:13:00,540 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend worker process died.
2022-01-09T12:13:00,543 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:13:00,543 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-01-09T12:13:00,556 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     worker.run_server()
2022-01-09T12:13:00,556 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-01-09T12:13:00,556 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-09T12:13:00,557 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-01-09T12:13:00,557 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-09T12:13:00,557 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-01-09T12:13:00,557 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-09T12:13:00,558 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-01-09T12:13:00,558 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-01-09T12:13:00,559 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/113541f89032406b85f32dfd7eafccd2/torchserve_handler.py", line 51, in initialize
2022-01-09T12:13:00,559 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.model = attempt_load(model_pt_path, map_location=self.device).autoshape(classes=[0])
2022-01-09T12:13:00,559 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - TypeError: autoshape() got an unexpected keyword argument 'classes'
2022-01-09T12:13:00,560 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:13:00,560 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:13:00,573 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:13:00,573 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:13:00,573 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:13:00,573 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:13:00,573 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:13:00,573 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:13:00,573 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:13:00,573 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:13:00,573 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:13:00,573 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:13:00,574 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:13:00,574 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:13:00,574 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-09T12:13:00,574 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-09T12:13:00,754 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:13:00,754 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:13:00,754 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:13:00,754 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:13:01,574 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:13:01,574 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:13:02,728 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:13:02,730 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]66903
2022-01-09T12:13:02,735 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:13:02,735 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:13:02,735 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:13:02,735 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:13:02,741 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:13:02,741 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:13:02,744 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726782744
2022-01-09T12:13:02,744 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726782744
2022-01-09T12:13:02,745 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:13:02,767 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:13:07,941 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:13:07,943 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:13:07,967 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:13:07,968 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:13:07,973 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend worker process died.
2022-01-09T12:13:07,974 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:13:07,974 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-01-09T12:13:07,975 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     worker.run_server()
2022-01-09T12:13:07,975 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-01-09T12:13:07,976 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-09T12:13:07,977 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-01-09T12:13:07,978 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-09T12:13:07,979 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-01-09T12:13:07,980 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-09T12:13:07,981 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-01-09T12:13:07,989 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-01-09T12:13:07,994 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/113541f89032406b85f32dfd7eafccd2/torchserve_handler.py", line 51, in initialize
2022-01-09T12:13:07,995 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.model = attempt_load(model_pt_path, map_location=self.device).autoshape(classes=[0])
2022-01-09T12:13:07,996 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - TypeError: autoshape() got an unexpected keyword argument 'classes'
2022-01-09T12:13:07,998 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:13:07,998 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:13:08,000 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:13:08,000 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:13:08,000 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:13:08,000 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:13:08,000 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:13:08,000 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:13:08,001 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:13:08,001 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:13:08,001 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:13:08,001 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:13:08,002 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:13:08,002 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:13:08,002 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-01-09T12:13:08,002 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-01-09T12:13:08,199 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:13:08,199 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:13:08,200 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:13:08,200 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:13:10,003 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:13:10,003 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:13:11,228 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:13:11,230 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]66956
2022-01-09T12:13:11,230 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:13:11,231 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:13:11,231 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:13:11,230 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:13:11,232 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:13:11,232 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:13:11,234 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726791234
2022-01-09T12:13:11,234 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726791234
2022-01-09T12:13:11,234 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:13:11,268 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:13:16,438 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:13:16,439 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:13:16,466 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:13:16,467 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:13:16,471 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend worker process died.
2022-01-09T12:13:16,471 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:13:16,472 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-01-09T12:13:16,472 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     worker.run_server()
2022-01-09T12:13:16,472 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-01-09T12:13:16,473 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-09T12:13:16,473 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-01-09T12:13:16,473 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-09T12:13:16,474 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-01-09T12:13:16,474 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-09T12:13:16,474 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-01-09T12:13:16,474 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-01-09T12:13:16,475 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/113541f89032406b85f32dfd7eafccd2/torchserve_handler.py", line 51, in initialize
2022-01-09T12:13:16,476 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.model = attempt_load(model_pt_path, map_location=self.device).autoshape(classes=[0])
2022-01-09T12:13:16,476 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - TypeError: autoshape() got an unexpected keyword argument 'classes'
2022-01-09T12:13:16,477 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:13:16,477 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:13:16,479 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:13:16,479 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:13:16,480 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:13:16,480 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:13:16,481 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:13:16,481 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:13:16,484 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:13:16,484 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:13:16,484 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:13:16,484 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:13:16,485 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:13:16,485 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:13:16,485 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-01-09T12:13:16,485 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-01-09T12:13:16,707 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:13:16,707 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:13:16,707 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:13:16,707 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:13:19,485 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:13:19,485 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:13:20,641 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:13:20,642 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]67022
2022-01-09T12:13:20,642 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:13:20,643 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:13:20,644 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:13:20,644 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:13:20,644 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:13:20,644 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:13:20,646 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:13:20,647 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726800647
2022-01-09T12:13:20,647 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726800647
2022-01-09T12:13:20,673 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:13:25,786 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:13:25,789 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:13:25,814 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:13:25,814 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:13:25,818 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend worker process died.
2022-01-09T12:13:25,819 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:13:25,820 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:13:25,820 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:13:25,821 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:13:25,821 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:13:25,822 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:13:25,822 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:13:25,824 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:13:25,824 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:13:25,824 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:13:25,824 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:13:25,824 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:13:25,824 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:13:25,824 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:13:25,824 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:13:25,825 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2022-01-09T12:13:25,825 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2022-01-09T12:13:25,819 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-01-09T12:13:25,831 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:13:25,831 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:13:26,041 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:13:26,041 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:13:30,825 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:13:30,825 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:13:32,085 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:13:32,085 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]67093
2022-01-09T12:13:32,085 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:13:32,086 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:13:32,086 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:13:32,086 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:13:32,086 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:13:32,086 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:13:32,088 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726812087
2022-01-09T12:13:32,088 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726812087
2022-01-09T12:13:32,089 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:13:32,125 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:13:38,317 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:13:38,320 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:13:38,348 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:13:38,349 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:13:38,353 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend worker process died.
2022-01-09T12:13:38,353 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:13:38,353 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-01-09T12:13:38,354 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     worker.run_server()
2022-01-09T12:13:38,354 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-01-09T12:13:38,354 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-09T12:13:38,354 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-01-09T12:13:38,354 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-09T12:13:38,355 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-01-09T12:13:38,355 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-09T12:13:38,355 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-01-09T12:13:38,356 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:13:38,356 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:13:38,358 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:13:38,358 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:13:38,367 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-01-09T12:13:38,368 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/113541f89032406b85f32dfd7eafccd2/torchserve_handler.py", line 51, in initialize
2022-01-09T12:13:38,369 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.model = attempt_load(model_pt_path, map_location=self.device).autoshape(classes=[0])
2022-01-09T12:13:38,369 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - TypeError: autoshape() got an unexpected keyword argument 'classes'
2022-01-09T12:13:38,359 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:13:38,359 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:13:38,370 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:13:38,370 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:13:38,370 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:13:38,370 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:13:38,370 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:13:38,370 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:13:38,371 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:13:38,371 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:13:38,371 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2022-01-09T12:13:38,371 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2022-01-09T12:13:38,602 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:13:38,602 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:13:38,602 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:13:38,602 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:13:46,372 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:13:46,372 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:13:47,586 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641726827
2022-01-09T12:13:47,587 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27193450927734|#Level:Host|#hostname:pressler-dell,timestamp:1641726827
2022-01-09T12:13:47,587 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.98180389404297|#Level:Host|#hostname:pressler-dell,timestamp:1641726827
2022-01-09T12:13:47,587 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641726827
2022-01-09T12:13:47,587 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19007.73828125|#Level:Host|#hostname:pressler-dell,timestamp:1641726827
2022-01-09T12:13:47,588 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:9365.10546875|#Level:Host|#hostname:pressler-dell,timestamp:1641726827
2022-01-09T12:13:47,588 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.5|#Level:Host|#hostname:pressler-dell,timestamp:1641726827
2022-01-09T12:13:47,600 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---
Traceback (most recent call last):
  File "/usr/lib/python3.9/logging/__init__.py", line 1087, in emit
    self.flush()
  File "/usr/lib/python3.9/logging/__init__.py", line 1067, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "/usr/lib/python3.9/site-packages/ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/usr/lib/python3.9/site-packages/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('66764', 1175339008)
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>
BrokenPipeError: [Errno 32] Broken pipe

2022-01-09T12:13:47,600 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---
Traceback (most recent call last):
  File "/usr/lib/python3.9/logging/__init__.py", line 1087, in emit
    self.flush()
  File "/usr/lib/python3.9/logging/__init__.py", line 1067, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "/usr/lib/python3.9/site-packages/ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/usr/lib/python3.9/site-packages/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('66764', 1175339008)
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>
BrokenPipeError: [Errno 32] Broken pipe

2022-01-09T12:13:47,851 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:13:47,855 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]67173
2022-01-09T12:13:47,857 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:13:47,858 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:13:47,858 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:13:47,858 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:13:47,858 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:13:47,858 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:13:47,864 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726827864
2022-01-09T12:13:47,864 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726827864
2022-01-09T12:13:47,867 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:13:47,868 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:13:53,752 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:13:53,753 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:13:53,780 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:13:53,781 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:13:53,785 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend worker process died.
2022-01-09T12:13:53,785 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:13:53,785 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:13:53,787 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:13:53,787 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-01-09T12:13:53,787 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:13:53,787 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     worker.run_server()
2022-01-09T12:13:53,787 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:13:53,787 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-01-09T12:13:53,787 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-09T12:13:53,787 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-01-09T12:13:53,788 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-09T12:13:53,788 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-01-09T12:13:53,788 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-09T12:13:53,788 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-01-09T12:13:53,787 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:13:53,787 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:13:53,793 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:13:53,793 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:13:53,793 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:13:53,793 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:13:53,793 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:13:53,793 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:13:53,792 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-01-09T12:13:53,798 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:13:53,798 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:13:53,799 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2022-01-09T12:13:53,799 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/113541f89032406b85f32dfd7eafccd2/torchserve_handler.py", line 51, in initialize
2022-01-09T12:13:53,799 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2022-01-09T12:13:53,800 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:13:53,800 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:13:53,987 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:13:53,987 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:14:26,812 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:14:26,812 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:14:26,906 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:14:26,906 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:14:26,914 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:14:26,914 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:14:26,944 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:14:26,944 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:14:27,575 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:14:27,575 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:14:27,576 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:14:27,576 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:14:27,577 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:14:27,577 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:14:27,577 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:14:27,577 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:14:27,586 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:14:27,586 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:14:27,588 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:14:27,588 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:14:28,383 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T12:14:28,384 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]67434
2022-01-09T12:14:28,385 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:14:28,385 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:14:28,386 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:14:28,386 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:14:28,399 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:14:28,399 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:14:28,467 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T12:14:28,474 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726868474
2022-01-09T12:14:28,474 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726868474
2022-01-09T12:14:28,521 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T12:14:28,823 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:14:28,823 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:14:28,823 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:14:28,823 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:14:28,824 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:14:28,824 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:14:28,824 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:14:28,824 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:14:28,826 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:14:28,826 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:14:28,826 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:14:28,826 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:14:28,858 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:14:28,858 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:14:28,860 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:14:28,860 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:14:28,868 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:14:28,868 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:14:28,870 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:14:28,870 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:14:28,877 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:14:28,877 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:14:29,114 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:14:29,114 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:14:29,189 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641726869
2022-01-09T12:14:29,189 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27183151245117|#Level:Host|#hostname:pressler-dell,timestamp:1641726869
2022-01-09T12:14:29,190 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.98190689086914|#Level:Host|#hostname:pressler-dell,timestamp:1641726869
2022-01-09T12:14:29,190 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641726869
2022-01-09T12:14:29,190 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19252.4375|#Level:Host|#hostname:pressler-dell,timestamp:1641726869
2022-01-09T12:14:29,190 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:9289.8828125|#Level:Host|#hostname:pressler-dell,timestamp:1641726869
2022-01-09T12:14:29,190 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:39.7|#Level:Host|#hostname:pressler-dell,timestamp:1641726869
2022-01-09T12:14:29,318 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 796
2022-01-09T12:14:29,318 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 796
2022-01-09T12:14:29,318 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:14:29,318 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:14:29,318 [INFO ] W-9000-scalenet_1.0 TS_METRICS - W-9000-scalenet_1.0.ms:1734|#Level:Host|#hostname:pressler-dell,timestamp:1641726869
2022-01-09T12:14:29,319 [INFO ] W-9000-scalenet_1.0 TS_METRICS - WorkerThreadTime.ms:49|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:14:29,673 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:14:29,674 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]67455
2022-01-09T12:14:29,675 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:14:29,675 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:14:29,675 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:14:29,675 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:14:29,676 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:14:29,676 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:14:29,678 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726869678
2022-01-09T12:14:29,678 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726869678
2022-01-09T12:14:29,678 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:14:29,707 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:14:35,738 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:14:35,743 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:14:35,761 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:14:35,762 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:14:35,765 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend worker process died.
2022-01-09T12:14:35,765 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:14:35,767 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-01-09T12:14:35,768 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     worker.run_server()
2022-01-09T12:14:35,768 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-01-09T12:14:35,768 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-01-09T12:14:35,768 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-01-09T12:14:35,769 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-01-09T12:14:35,769 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-01-09T12:14:35,769 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-01-09T12:14:35,769 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-01-09T12:14:35,769 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     initialize_fn(service.context)
2022-01-09T12:14:35,770 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/ebc08ee1cf5740febdde43d47ee9a3a6/torchserve_handler.py", line 51, in initialize
2022-01-09T12:14:35,766 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:14:35,766 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-01-09T12:14:35,777 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:14:35,777 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-01-09T12:14:35,791 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     self.model = attempt_load(model_pt_path, map_location=self.device).autoshape([0])
2022-01-09T12:14:35,791 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - TypeError: autoshape() takes 1 positional argument but 2 were given
2022-01-09T12:14:35,777 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:14:35,777 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2022-01-09T12:14:35,822 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:14:35,822 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: yolov5, error: Worker died.
2022-01-09T12:14:35,823 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:14:35,823 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_STOPPED
2022-01-09T12:14:35,824 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:14:35,824 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stderr
2022-01-09T12:14:35,824 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:14:35,824 [WARN ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-yolov5_0.1-stdout
2022-01-09T12:14:35,827 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-09T12:14:35,827 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-01-09T12:14:36,003 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:14:36,003 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:14:36,003 [INFO ] W-9001-yolov5_0.1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stderr
2022-01-09T12:14:36,003 [INFO ] W-9001-yolov5_0.1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-yolov5_0.1-stdout
2022-01-09T12:14:36,828 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:14:36,828 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:14:38,268 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:14:38,272 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]67526
2022-01-09T12:14:38,273 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:14:38,273 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:14:38,273 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STOPPED -> WORKER_STARTED
2022-01-09T12:14:38,275 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:14:38,275 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:14:38,275 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:14:38,280 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:14:38,280 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726878280
2022-01-09T12:14:38,280 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726878280
2022-01-09T12:14:38,337 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:16:13,756 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:16:13,756 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:16:13,841 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:16:13,841 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:16:13,847 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:16:13,847 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:16:13,880 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:16:13,880 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:16:14,628 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:16:14,628 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:16:14,629 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:16:14,629 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:16:14,630 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:16:14,630 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:16:14,630 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:16:14,630 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:16:14,660 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:16:14,660 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:16:14,665 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:16:14,665 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:16:15,952 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T12:16:15,953 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]68026
2022-01-09T12:16:15,953 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:16:15,953 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:16:15,954 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:16:15,954 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:16:15,974 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:16:15,974 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:16:16,079 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T12:16:16,085 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726976085
2022-01-09T12:16:16,085 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726976085
2022-01-09T12:16:16,128 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T12:16:16,371 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:16:16,371 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:16:16,372 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:16:16,372 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:16:16,372 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:16:16,372 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:16:16,373 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:16:16,373 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:16:16,374 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:16:16,374 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:16:16,384 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:16:16,384 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:16:16,404 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:16:16,404 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:16:16,407 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:16:16,407 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:16:16,424 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:16:16,424 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:16:16,425 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:16:16,425 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:16:16,428 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:16:16,428 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:16:16,780 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:16:16,780 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:16:16,873 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641726976
2022-01-09T12:16:16,875 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27164840698242|#Level:Host|#hostname:pressler-dell,timestamp:1641726976
2022-01-09T12:16:16,881 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9820899963379|#Level:Host|#hostname:pressler-dell,timestamp:1641726976
2022-01-09T12:16:16,883 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641726976
2022-01-09T12:16:16,885 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19073.78125|#Level:Host|#hostname:pressler-dell,timestamp:1641726976
2022-01-09T12:16:16,888 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:9359.79296875|#Level:Host|#hostname:pressler-dell,timestamp:1641726976
2022-01-09T12:16:16,891 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.2|#Level:Host|#hostname:pressler-dell,timestamp:1641726976
2022-01-09T12:16:17,090 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 950
2022-01-09T12:16:17,090 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 950
2022-01-09T12:16:17,090 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:16:17,090 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:16:17,091 [INFO ] W-9000-scalenet_1.0 TS_METRICS - W-9000-scalenet_1.0.ms:2444|#Level:Host|#hostname:pressler-dell,timestamp:1641726977
2022-01-09T12:16:17,091 [INFO ] W-9000-scalenet_1.0 TS_METRICS - WorkerThreadTime.ms:56|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:16:17,480 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:16:17,481 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]68042
2022-01-09T12:16:17,481 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:16:17,481 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:16:17,482 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:16:17,482 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:16:17,481 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:16:17,484 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726977484
2022-01-09T12:16:17,484 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:16:17,484 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726977484
2022-01-09T12:16:17,484 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:16:17,510 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:16:22,742 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:16:22,746 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:16:22,768 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:16:22,768 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:16:23,225 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:16:23,225 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:16:23,225 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 224 layers, 7056607 parameters, 7056607 gradients, 16.3 GFLOPS
2022-01-09T12:16:23,229 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:16:23,229 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model file /tmp/models/f8e090cdc9ca49048a1e6315277b489c/yolov5s.pt loaded successfully
2022-01-09T12:16:23,229 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5719
2022-01-09T12:16:23,229 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5719
2022-01-09T12:16:23,230 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:16:23,230 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:16:23,230 [INFO ] W-9001-yolov5_0.1 TS_METRICS - W-9001-yolov5_0.1.ms:6857|#Level:Host|#hostname:pressler-dell,timestamp:1641726983
2022-01-09T12:16:23,231 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:28|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:16:23,231 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726983231
2022-01-09T12:16:23,231 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641726983231
2022-01-09T12:16:23,238 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641726983
2022-01-09T12:16:23,403 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - tensor([[1318.59924,  203.64111, 1585.54492,  759.35504],
2022-01-09T12:16:23,403 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [ 508.02631,  266.97983,  715.44958,  886.97882]], device='cuda:0')
2022-01-09T12:16:23,404 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 166
2022-01-09T12:16:23,404 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - tensor([[ 559.15881,  305.92285,  634.93896,  386.12317],
2022-01-09T12:16:23,404 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 166
2022-01-09T12:16:23,404 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [1481.50989,  227.25751, 1542.32336,  289.98309]], device='cuda:0')
2022-01-09T12:16:23,405 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - tensor([[0.00000, 0.04726],
2022-01-09T12:16:23,405 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -         [0.02571, 0.00000]], device='cuda:0')
2022-01-09T12:16:23,405 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - tensor([1, 0], device='cuda:0')
2022-01-09T12:16:23,406 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model: yolov5, Invalid return type: <class 'NoneType'>.
2022-01-09T12:16:23,410 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:54396 "POST /predictions/yolov5 HTTP/1.1" 503 5277
2022-01-09T12:16:23,412 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:16:23,413 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 4973601193, Inference time ns: 5155478876
2022-01-09T12:16:23,413 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 4973601193, Inference time ns: 5155478876
2022-01-09T12:16:23,413 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:16|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:17:16,813 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727036
2022-01-09T12:17:16,815 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27158737182617|#Level:Host|#hostname:pressler-dell,timestamp:1641727036
2022-01-09T12:17:16,824 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.98215103149414|#Level:Host|#hostname:pressler-dell,timestamp:1641727036
2022-01-09T12:17:16,827 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727036
2022-01-09T12:17:16,828 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17013.1953125|#Level:Host|#hostname:pressler-dell,timestamp:1641727036
2022-01-09T12:17:16,829 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11431.52734375|#Level:Host|#hostname:pressler-dell,timestamp:1641727036
2022-01-09T12:17:16,829 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:46.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727036
2022-01-09T12:17:20,366 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:17:20,366 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:17:20,454 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:17:20,454 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:17:20,461 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:17:20,461 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:17:20,489 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:17:20,489 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:17:21,070 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:17:21,070 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:17:21,070 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:17:21,070 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:17:21,071 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:17:21,071 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:17:21,071 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:17:21,071 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:17:21,079 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:17:21,079 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:17:21,101 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:17:21,101 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:17:32,993 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:17:32,993 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:17:33,075 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:17:33,075 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:17:33,082 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:17:33,082 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:17:33,111 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:17:33,111 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:17:33,667 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:17:33,667 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:17:33,667 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:17:33,667 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:17:33,668 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:17:33,668 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:17:33,668 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:17:33,668 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:17:33,678 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:17:33,678 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:17:33,679 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:17:33,679 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:17:34,435 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T12:17:34,437 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]68475
2022-01-09T12:17:34,437 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:17:34,437 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:17:34,437 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:17:34,437 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:17:34,450 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:17:34,450 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:17:34,518 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T12:17:34,523 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727054523
2022-01-09T12:17:34,523 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727054523
2022-01-09T12:17:34,562 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T12:17:34,943 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:17:34,943 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:17:34,943 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:17:34,943 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:17:34,943 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:17:34,943 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:17:34,943 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:17:34,943 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:17:34,946 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:17:34,946 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:17:34,946 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:17:34,946 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:17:34,997 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:17:34,997 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:17:34,998 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:17:34,998 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:17:35,011 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:17:35,011 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:17:35,012 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:17:35,012 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:17:35,015 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:17:35,015 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:17:35,351 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:17:35,351 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:17:35,427 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727055
2022-01-09T12:17:35,428 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27157211303711|#Level:Host|#hostname:pressler-dell,timestamp:1641727055
2022-01-09T12:17:35,428 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9821662902832|#Level:Host|#hostname:pressler-dell,timestamp:1641727055
2022-01-09T12:17:35,429 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727055
2022-01-09T12:17:35,429 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19124.85546875|#Level:Host|#hostname:pressler-dell,timestamp:1641727055
2022-01-09T12:17:35,430 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:9410.29296875|#Level:Host|#hostname:pressler-dell,timestamp:1641727055
2022-01-09T12:17:35,431 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.1|#Level:Host|#hostname:pressler-dell,timestamp:1641727055
2022-01-09T12:17:35,467 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 888
2022-01-09T12:17:35,467 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 888
2022-01-09T12:17:35,468 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:17:35,468 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:17:35,468 [INFO ] W-9000-scalenet_1.0 TS_METRICS - W-9000-scalenet_1.0.ms:1793|#Level:Host|#hostname:pressler-dell,timestamp:1641727055
2022-01-09T12:17:35,469 [INFO ] W-9000-scalenet_1.0 TS_METRICS - WorkerThreadTime.ms:58|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:17:35,890 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:17:35,891 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]68494
2022-01-09T12:17:35,891 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:17:35,891 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:17:35,891 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:17:35,891 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:17:35,891 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:17:35,891 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:17:35,893 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727055893
2022-01-09T12:17:35,893 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:17:35,893 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727055893
2022-01-09T12:17:35,920 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:17:41,718 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:17:41,721 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:17:41,741 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:17:41,744 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:17:42,215 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:17:42,216 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:17:42,217 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 224 layers, 7056607 parameters, 7056607 gradients, 16.3 GFLOPS
2022-01-09T12:17:42,218 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6299
2022-01-09T12:17:42,218 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6299
2022-01-09T12:17:42,219 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:17:42,219 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:17:42,218 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:17:42,221 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model file /tmp/models/a7d0eafd74f743678e4550ba5c5498f9/yolov5s.pt loaded successfully
2022-01-09T12:17:42,221 [INFO ] W-9001-yolov5_0.1 TS_METRICS - W-9001-yolov5_0.1.ms:7277|#Level:Host|#hostname:pressler-dell,timestamp:1641727062
2022-01-09T12:17:42,222 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:30|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:17:42,227 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727062227
2022-01-09T12:17:42,227 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727062227
2022-01-09T12:17:42,251 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641727062
2022-01-09T12:17:42,458 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - 0 tensor(1, device='cuda:0')
2022-01-09T12:17:42,458 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - 1 tensor(0, device='cuda:0')
2022-01-09T12:17:42,458 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model: yolov5, Invalid return type: <class 'NoneType'>.
2022-01-09T12:17:42,461 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 212
2022-01-09T12:17:42,461 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 212
2022-01-09T12:17:42,472 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:54444 "POST /predictions/yolov5 HTTP/1.1" 503 5280
2022-01-09T12:17:42,474 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:17:42,499 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 4850079304, Inference time ns: 5122283308
2022-01-09T12:17:42,499 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 4850079304, Inference time ns: 5122283308
2022-01-09T12:17:42,506 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:67|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:18:35,410 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727115
2022-01-09T12:18:35,411 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27151489257812|#Level:Host|#hostname:pressler-dell,timestamp:1641727115
2022-01-09T12:18:35,411 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9822235107422|#Level:Host|#hostname:pressler-dell,timestamp:1641727115
2022-01-09T12:18:35,411 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727115
2022-01-09T12:18:35,411 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17206.671875|#Level:Host|#hostname:pressler-dell,timestamp:1641727115
2022-01-09T12:18:35,411 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11183.74609375|#Level:Host|#hostname:pressler-dell,timestamp:1641727115
2022-01-09T12:18:35,411 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:46.1|#Level:Host|#hostname:pressler-dell,timestamp:1641727115
2022-01-09T12:19:35,408 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727175
2022-01-09T12:19:35,408 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27138900756836|#Level:Host|#hostname:pressler-dell,timestamp:1641727175
2022-01-09T12:19:35,408 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.98234939575195|#Level:Host|#hostname:pressler-dell,timestamp:1641727175
2022-01-09T12:19:35,408 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727175
2022-01-09T12:19:35,409 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17085.5078125|#Level:Host|#hostname:pressler-dell,timestamp:1641727175
2022-01-09T12:19:35,409 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11275.4453125|#Level:Host|#hostname:pressler-dell,timestamp:1641727175
2022-01-09T12:19:35,409 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:46.5|#Level:Host|#hostname:pressler-dell,timestamp:1641727175
2022-01-09T12:20:35,411 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727235
2022-01-09T12:20:35,411 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27112579345703|#Level:Host|#hostname:pressler-dell,timestamp:1641727235
2022-01-09T12:20:35,412 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9826126098633|#Level:Host|#hostname:pressler-dell,timestamp:1641727235
2022-01-09T12:20:35,412 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727235
2022-01-09T12:20:35,412 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17380.8046875|#Level:Host|#hostname:pressler-dell,timestamp:1641727235
2022-01-09T12:20:35,412 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11113.83203125|#Level:Host|#hostname:pressler-dell,timestamp:1641727235
2022-01-09T12:20:35,412 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:45.6|#Level:Host|#hostname:pressler-dell,timestamp:1641727235
2022-01-09T12:21:35,408 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727295
2022-01-09T12:21:35,410 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27109146118164|#Level:Host|#hostname:pressler-dell,timestamp:1641727295
2022-01-09T12:21:35,415 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9826469421387|#Level:Host|#hostname:pressler-dell,timestamp:1641727295
2022-01-09T12:21:35,417 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727295
2022-01-09T12:21:35,420 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17048.54296875|#Level:Host|#hostname:pressler-dell,timestamp:1641727295
2022-01-09T12:21:35,424 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11394.078125|#Level:Host|#hostname:pressler-dell,timestamp:1641727295
2022-01-09T12:21:35,426 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:46.6|#Level:Host|#hostname:pressler-dell,timestamp:1641727295
2022-01-09T12:22:35,415 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727355
2022-01-09T12:22:35,415 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27103042602539|#Level:Host|#hostname:pressler-dell,timestamp:1641727355
2022-01-09T12:22:35,416 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9827079772949|#Level:Host|#hostname:pressler-dell,timestamp:1641727355
2022-01-09T12:22:35,416 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727355
2022-01-09T12:22:35,416 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:16995.19921875|#Level:Host|#hostname:pressler-dell,timestamp:1641727355
2022-01-09T12:22:35,416 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11511.2578125|#Level:Host|#hostname:pressler-dell,timestamp:1641727355
2022-01-09T12:22:35,416 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:46.8|#Level:Host|#hostname:pressler-dell,timestamp:1641727355
2022-01-09T12:23:35,409 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727415
2022-01-09T12:23:35,411 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:76.27103042602539|#Level:Host|#hostname:pressler-dell,timestamp:1641727415
2022-01-09T12:23:35,413 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:421.9827079772949|#Level:Host|#hostname:pressler-dell,timestamp:1641727415
2022-01-09T12:23:35,414 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727415
2022-01-09T12:23:35,414 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:17341.63671875|#Level:Host|#hostname:pressler-dell,timestamp:1641727415
2022-01-09T12:23:35,414 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:11170.9453125|#Level:Host|#hostname:pressler-dell,timestamp:1641727415
2022-01-09T12:23:35,414 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:45.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727415
2022-01-09T12:24:35,466 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727475
2022-01-09T12:24:35,467 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27097702026367|#Level:Host|#hostname:pressler-dell,timestamp:1641727475
2022-01-09T12:24:35,467 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.98276138305664|#Level:Host|#hostname:pressler-dell,timestamp:1641727475
2022-01-09T12:24:35,468 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727475
2022-01-09T12:24:35,468 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17200.1875|#Level:Host|#hostname:pressler-dell,timestamp:1641727475
2022-01-09T12:24:35,468 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11297.33203125|#Level:Host|#hostname:pressler-dell,timestamp:1641727475
2022-01-09T12:24:35,469 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:46.1|#Level:Host|#hostname:pressler-dell,timestamp:1641727475
2022-01-09T12:25:08,102 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:25:08,102 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:25:08,209 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:25:08,209 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:25:08,217 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:25:08,217 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:25:08,263 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:25:08,263 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:25:08,847 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:25:08,847 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:25:08,848 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:25:08,848 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:25:08,848 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:25:08,848 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:25:08,848 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:25:08,848 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:25:08,857 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:25:08,857 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:25:08,858 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:25:08,858 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:25:09,633 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T12:25:09,634 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]69981
2022-01-09T12:25:09,634 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:25:09,635 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:25:09,635 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:25:09,635 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:25:09,651 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:25:09,651 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:25:09,709 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T12:25:09,715 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727509715
2022-01-09T12:25:09,715 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727509715
2022-01-09T12:25:09,758 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T12:25:10,060 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:25:10,060 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:25:10,060 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:25:10,060 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:25:10,060 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:25:10,060 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:25:10,061 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:25:10,061 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:25:10,063 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:25:10,063 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:25:10,065 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:25:10,065 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:25:10,078 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:25:10,078 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:25:10,080 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:25:10,080 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:25:10,098 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:25:10,098 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:25:10,098 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:25:10,098 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:25:10,100 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:25:10,100 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:25:10,351 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:25:10,351 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:25:10,437 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727510
2022-01-09T12:25:10,439 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27095413208008|#Level:Host|#hostname:pressler-dell,timestamp:1641727510
2022-01-09T12:25:10,442 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.98278427124023|#Level:Host|#hostname:pressler-dell,timestamp:1641727510
2022-01-09T12:25:10,442 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727510
2022-01-09T12:25:10,444 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19013.265625|#Level:Host|#hostname:pressler-dell,timestamp:1641727510
2022-01-09T12:25:10,445 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:9519.58203125|#Level:Host|#hostname:pressler-dell,timestamp:1641727510
2022-01-09T12:25:10,447 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.4|#Level:Host|#hostname:pressler-dell,timestamp:1641727510
2022-01-09T12:25:10,561 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 777
2022-01-09T12:25:10,561 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 777
2022-01-09T12:25:10,562 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:25:10,562 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:25:10,563 [INFO ] W-9000-scalenet_1.0 TS_METRICS - W-9000-scalenet_1.0.ms:1708|#Level:Host|#hostname:pressler-dell,timestamp:1641727510
2022-01-09T12:25:10,571 [INFO ] W-9000-scalenet_1.0 TS_METRICS - WorkerThreadTime.ms:79|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:25:11,230 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:25:11,237 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]69998
2022-01-09T12:25:11,240 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:25:11,240 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:25:11,240 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:25:11,240 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:25:11,240 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:25:11,246 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:25:11,248 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727511248
2022-01-09T12:25:11,248 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727511248
2022-01-09T12:25:11,250 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:25:11,314 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:25:16,678 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:25:16,681 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:25:16,697 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:25:16,698 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:25:17,192 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:25:17,192 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:25:17,193 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 224 layers, 7056607 parameters, 7056607 gradients, 16.3 GFLOPS
2022-01-09T12:25:17,195 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:25:17,196 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5865
2022-01-09T12:25:17,196 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5865
2022-01-09T12:25:17,196 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model file /tmp/models/0cc30032ddae4ca7ba99c29e2223db9c/yolov5s.pt loaded successfully
2022-01-09T12:25:17,196 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:25:17,196 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:25:17,197 [INFO ] W-9001-yolov5_0.1 TS_METRICS - W-9001-yolov5_0.1.ms:7136|#Level:Host|#hostname:pressler-dell,timestamp:1641727517
2022-01-09T12:25:17,198 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:85|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:25:17,201 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727517201
2022-01-09T12:25:17,201 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727517201
2022-01-09T12:25:17,213 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641727517
2022-01-09T12:25:17,375 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Invoking custom service failed.
2022-01-09T12:25:17,376 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:25:17,376 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 164
2022-01-09T12:25:17,376 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 164
2022-01-09T12:25:17,376 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-01-09T12:25:17,381 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-01-09T12:25:17,384 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:54550 "POST /predictions/yolov5 HTTP/1.1" 503 3995
2022-01-09T12:25:17,387 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/0cc30032ddae4ca7ba99c29e2223db9c/torchserve_handler.py", line 128, in handle
2022-01-09T12:25:17,387 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     output = self.postprocess(predictions, masks, result)
2022-01-09T12:25:17,388 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/0cc30032ddae4ca7ba99c29e2223db9c/torchserve_handler.py", line 152, in postprocess
2022-01-09T12:25:17,389 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:25:17,392 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 3671793305, Inference time ns: 3862663615
2022-01-09T12:25:17,392 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 3671793305, Inference time ns: 3862663615
2022-01-09T12:25:17,393 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:28|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:25:17,397 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     _retval['class'] = masks.pred[batch_idx][maskToPerson.index(i)][5]
2022-01-09T12:25:17,398 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - AttributeError: 'Tensor' object has no attribute 'index'
2022-01-09T12:26:03,111 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:26:03,111 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:26:03,194 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:26:03,194 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:26:03,201 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:26:03,201 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:26:03,229 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:26:03,229 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:26:03,791 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:26:03,791 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:26:03,792 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:26:03,792 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:26:03,792 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:26:03,792 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:26:03,792 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:26:03,792 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:26:03,802 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:26:03,802 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:26:03,804 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:26:03,804 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:26:04,932 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T12:26:04,934 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]70394
2022-01-09T12:26:04,936 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:26:04,936 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:26:04,937 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:26:04,948 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:26:04,959 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:26:04,959 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:26:05,158 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T12:26:05,197 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727565197
2022-01-09T12:26:05,197 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727565197
2022-01-09T12:26:05,268 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T12:26:05,528 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:26:05,528 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:26:05,529 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:26:05,529 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:26:05,529 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:26:05,529 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:26:05,529 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:26:05,529 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:26:05,538 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:26:05,538 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:26:05,546 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:26:05,546 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:26:05,581 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:26:05,581 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:26:05,584 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:26:05,584 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:26:05,599 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:26:05,599 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:26:05,601 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:26:05,601 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:26:05,603 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:26:05,603 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:26:05,912 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:26:05,912 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:26:05,999 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727565
2022-01-09T12:26:06,000 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27052307128906|#Level:Host|#hostname:pressler-dell,timestamp:1641727565
2022-01-09T12:26:06,003 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.98321533203125|#Level:Host|#hostname:pressler-dell,timestamp:1641727565
2022-01-09T12:26:06,004 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727565
2022-01-09T12:26:06,009 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:18858.71875|#Level:Host|#hostname:pressler-dell,timestamp:1641727565
2022-01-09T12:26:06,011 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:9499.81640625|#Level:Host|#hostname:pressler-dell,timestamp:1641727565
2022-01-09T12:26:06,013 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.9|#Level:Host|#hostname:pressler-dell,timestamp:1641727565
2022-01-09T12:26:06,295 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1013
2022-01-09T12:26:06,295 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1013
2022-01-09T12:26:06,295 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:26:06,295 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:26:06,295 [INFO ] W-9000-scalenet_1.0 TS_METRICS - W-9000-scalenet_1.0.ms:2495|#Level:Host|#hostname:pressler-dell,timestamp:1641727566
2022-01-09T12:26:06,296 [INFO ] W-9000-scalenet_1.0 TS_METRICS - WorkerThreadTime.ms:86|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:26:06,513 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:26:06,514 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]70414
2022-01-09T12:26:06,514 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:26:06,514 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:26:06,514 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:26:06,514 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:26:06,515 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:26:06,515 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:26:06,518 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727566518
2022-01-09T12:26:06,518 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:26:06,518 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727566518
2022-01-09T12:26:06,546 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:26:11,404 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:26:11,406 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:26:11,426 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:26:11,427 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:26:11,906 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:26:11,909 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:26:11,910 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 224 layers, 7056607 parameters, 7056607 gradients, 16.3 GFLOPS
2022-01-09T12:26:11,910 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5364
2022-01-09T12:26:11,910 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5364
2022-01-09T12:26:11,910 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:26:11,910 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:26:11,910 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:26:11,910 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model file /tmp/models/c7923a2c215144ed8ed392be784e64df/yolov5s.pt loaded successfully
2022-01-09T12:26:11,910 [INFO ] W-9001-yolov5_0.1 TS_METRICS - W-9001-yolov5_0.1.ms:6380|#Level:Host|#hostname:pressler-dell,timestamp:1641727571
2022-01-09T12:26:11,911 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:29|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:26:11,911 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727571911
2022-01-09T12:26:11,911 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727571911
2022-01-09T12:26:11,918 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641727571
2022-01-09T12:26:12,080 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Unable to serialize model output.
2022-01-09T12:26:12,080 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:26:12,080 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 130, in create_predict_response
2022-01-09T12:26:12,080 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     json_value = json.dumps(val, indent=2).encode("utf-8")
2022-01-09T12:26:12,081 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/json/__init__.py", line 234, in dumps
2022-01-09T12:26:12,081 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     return cls(
2022-01-09T12:26:12,081 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/json/encoder.py", line 201, in encode
2022-01-09T12:26:12,082 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     chunks = list(chunks)
2022-01-09T12:26:12,082 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/json/encoder.py", line 429, in _iterencode
2022-01-09T12:26:12,083 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     yield from _iterencode_list(o, _current_indent_level)
2022-01-09T12:26:12,083 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/json/encoder.py", line 325, in _iterencode_list
2022-01-09T12:26:12,084 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     yield from chunks
2022-01-09T12:26:12,084 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/json/encoder.py", line 325, in _iterencode_list
2022-01-09T12:26:12,084 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     yield from chunks
2022-01-09T12:26:12,084 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/json/encoder.py", line 405, in _iterencode_dict
2022-01-09T12:26:12,084 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     yield from chunks
2022-01-09T12:26:12,084 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/json/encoder.py", line 438, in _iterencode
2022-01-09T12:26:12,085 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     o = _default(o)
2022-01-09T12:26:12,085 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/json/encoder.py", line 179, in default
2022-01-09T12:26:12,085 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     raise TypeError(f'Object of type {o.__class__.__name__} '
2022-01-09T12:26:12,086 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - TypeError: Object of type Tensor is not JSON serializable
2022-01-09T12:26:12,088 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 172
2022-01-09T12:26:12,088 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 172
2022-01-09T12:26:12,089 [INFO ] W-9001-yolov5_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:160.27|#ModelName:yolov5,Level:Model|#hostname:pressler-dell,requestID:5b8dbf17-c77f-40ae-8db8-09fab685815c,timestamp:1641727572
2022-01-09T12:26:12,106 [INFO ] W-9001-yolov5_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:160.41|#ModelName:yolov5,Level:Model|#hostname:pressler-dell,requestID:5b8dbf17-c77f-40ae-8db8-09fab685815c,timestamp:1641727572
2022-01-09T12:26:12,110 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:54590 "POST /predictions/yolov5 HTTP/1.1" 503 3837
2022-01-09T12:26:12,112 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:26:12,112 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 3454428049, Inference time ns: 3655054141
2022-01-09T12:26:12,112 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 3454428049, Inference time ns: 3655054141
2022-01-09T12:26:12,117 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:33|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:26:46,293 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-01-09T12:26:46,293 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-01-09T12:26:46,295 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2022-01-09T12:26:46,295 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2022-01-09T12:26:46,296 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-01-09T12:26:46,296 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-01-09T12:26:56,714 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:26:56,714 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:26:56,813 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:26:56,813 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:26:56,820 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:26:56,820 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:26:56,849 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:26:56,849 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:26:57,459 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:26:57,459 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:26:57,461 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:26:57,461 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:26:57,461 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:26:57,461 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:26:57,461 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:26:57,461 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:26:57,469 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:26:57,469 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:26:57,472 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:26:57,472 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:26:58,247 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T12:26:58,248 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]70682
2022-01-09T12:26:58,248 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:26:58,248 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:26:58,249 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:26:58,249 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:26:58,264 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:26:58,264 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:26:58,326 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T12:26:58,336 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727618336
2022-01-09T12:26:58,336 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727618336
2022-01-09T12:26:58,384 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T12:26:58,680 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:26:58,680 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:26:58,680 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:26:58,680 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:26:58,680 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:26:58,680 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:26:58,682 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:26:58,682 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:26:58,687 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:26:58,687 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:26:58,689 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:26:58,689 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:26:58,716 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:26:58,716 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:26:58,717 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:26:58,717 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:26:58,732 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:26:58,732 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:26:58,733 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:26:58,733 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:26:58,737 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:26:58,737 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:26:59,434 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:26:59,434 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:26:59,687 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727619
2022-01-09T12:26:59,690 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27046203613281|#Level:Host|#hostname:pressler-dell,timestamp:1641727619
2022-01-09T12:26:59,696 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9832763671875|#Level:Host|#hostname:pressler-dell,timestamp:1641727619
2022-01-09T12:26:59,698 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727619
2022-01-09T12:26:59,700 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:18849.84765625|#Level:Host|#hostname:pressler-dell,timestamp:1641727619
2022-01-09T12:26:59,702 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:9450.28125|#Level:Host|#hostname:pressler-dell,timestamp:1641727619
2022-01-09T12:26:59,706 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:40.9|#Level:Host|#hostname:pressler-dell,timestamp:1641727619
2022-01-09T12:26:59,778 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1388
2022-01-09T12:26:59,778 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1388
2022-01-09T12:26:59,779 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:26:59,779 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:26:59,779 [INFO ] W-9000-scalenet_1.0 TS_METRICS - W-9000-scalenet_1.0.ms:2311|#Level:Host|#hostname:pressler-dell,timestamp:1641727619
2022-01-09T12:26:59,780 [INFO ] W-9000-scalenet_1.0 TS_METRICS - WorkerThreadTime.ms:56|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:27:00,494 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:27:00,495 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]70701
2022-01-09T12:27:00,496 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:27:00,496 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:27:00,496 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:27:00,496 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:27:00,496 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:27:00,497 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:27:00,499 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727620499
2022-01-09T12:27:00,499 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:27:00,499 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727620499
2022-01-09T12:27:00,529 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:27:05,868 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:27:05,869 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:27:05,894 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:27:05,896 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:27:06,355 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:27:06,356 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:27:06,356 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 224 layers, 7056607 parameters, 7056607 gradients, 16.3 GFLOPS
2022-01-09T12:27:06,359 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:27:06,360 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5819
2022-01-09T12:27:06,360 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model file /tmp/models/90bc2e83ec5f43049e19cdafdb7a5a68/yolov5s.pt loaded successfully
2022-01-09T12:27:06,360 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5819
2022-01-09T12:27:06,360 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:27:06,360 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:27:06,361 [INFO ] W-9001-yolov5_0.1 TS_METRICS - W-9001-yolov5_0.1.ms:7678|#Level:Host|#hostname:pressler-dell,timestamp:1641727626
2022-01-09T12:27:06,362 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:44|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:27:06,363 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727626363
2022-01-09T12:27:06,363 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727626363
2022-01-09T12:27:06,370 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641727626
2022-01-09T12:27:06,532 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 164
2022-01-09T12:27:06,531 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Invoking custom service failed.
2022-01-09T12:27:06,532 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Traceback (most recent call last):
2022-01-09T12:27:06,532 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/usr/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-01-09T12:27:06,532 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-01-09T12:27:06,533 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/90bc2e83ec5f43049e19cdafdb7a5a68/torchserve_handler.py", line 128, in handle
2022-01-09T12:27:06,533 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     output = self.postprocess(predictions, masks, result)
2022-01-09T12:27:06,533 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -   File "/tmp/models/90bc2e83ec5f43049e19cdafdb7a5a68/torchserve_handler.py", line 152, in postprocess
2022-01-09T12:27:06,533 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG -     _retval['class'] = masks.names[masks.pred[batch_idx][maskToPerson.index(i)][5].item()]
2022-01-09T12:27:06,535 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - TypeError: list indices must be integers or slices, not float
2022-01-09T12:27:06,532 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 164
2022-01-09T12:27:06,551 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:54606 "POST /predictions/yolov5 HTTP/1.1" 503 6466
2022-01-09T12:27:06,553 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:27:06,557 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 6129277556, Inference time ns: 6323692179
2022-01-09T12:27:06,557 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 6129277556, Inference time ns: 6323692179
2022-01-09T12:27:06,560 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:31|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:27:20,695 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-01-09T12:27:20,695 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-01-09T12:27:20,697 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-01-09T12:27:20,697 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-01-09T12:27:20,697 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2022-01-09T12:27:20,697 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2022-01-09T12:27:30,750 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:27:30,750 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-01-09T12:27:30,872 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:27:30,872 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.1
TS Home: /usr/lib/python3.9/site-packages
Current directory: /home/pressler/Desktop/babyelefant/torchserve
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 4
Max heap size: 7984 M
Python executable: /usr/bin/python3.9
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Initial Models: scalenet.mar,yolov5.mar
Log dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Metrics dir: /home/pressler/Desktop/babyelefant/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/pressler/Desktop/babyelefant/torchserve/model_store
Model config: N/A
2022-01-09T12:27:30,882 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:27:30,882 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-01-09T12:27:30,915 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:27:30,915 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: scalenet.mar
2022-01-09T12:27:31,518 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:27:31,518 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model scalenet
2022-01-09T12:27:31,518 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:27:31,518 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model scalenet
2022-01-09T12:27:31,518 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:27:31,518 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model scalenet loaded.
2022-01-09T12:27:31,519 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:27:31,519 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: scalenet, count: 1
2022-01-09T12:27:31,527 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:27:31,527 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: yolov5.mar
2022-01-09T12:27:31,531 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:27:31,531 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000]
2022-01-09T12:27:32,361 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2022-01-09T12:27:32,361 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - [PID]70926
2022-01-09T12:27:32,362 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:27:32,362 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:27:32,362 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:27:32,362 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change null -> WORKER_STARTED
2022-01-09T12:27:32,378 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:27:32,378 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2022-01-09T12:27:32,441 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2022-01-09T12:27:32,446 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727652446
2022-01-09T12:27:32,446 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727652446
2022-01-09T12:27:32,494 [INFO ] W-9000-scalenet_1.0-stdout MODEL_LOG - model_name: scalenet, batchSize: 1
2022-01-09T12:27:32,780 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:27:32,780 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 0.1 for model yolov5
2022-01-09T12:27:32,780 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:27:32,780 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 0.1 for model yolov5
2022-01-09T12:27:32,781 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:27:32,781 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model yolov5 loaded.
2022-01-09T12:27:32,781 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:27:32,781 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: yolov5, count: 1
2022-01-09T12:27:32,783 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:27:32,783 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2022-01-09T12:27:32,784 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:27:32,784 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/usr/bin/python3.9, /usr/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9001]
2022-01-09T12:27:32,817 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:27:32,817 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-01-09T12:27:32,817 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:27:32,817 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2022-01-09T12:27:32,835 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:27:32,835 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-01-09T12:27:32,836 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:27:32,836 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2022-01-09T12:27:32,848 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:27:32,848 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-01-09T12:27:33,095 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:27:33,095 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-01-09T12:27:33,168 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727653
2022-01-09T12:27:33,168 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.2703971862793|#Level:Host|#hostname:pressler-dell,timestamp:1641727653
2022-01-09T12:27:33,168 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.983341217041|#Level:Host|#hostname:pressler-dell,timestamp:1641727653
2022-01-09T12:27:33,169 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727653
2022-01-09T12:27:33,169 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:19207.1171875|#Level:Host|#hostname:pressler-dell,timestamp:1641727653
2022-01-09T12:27:33,169 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:9313.296875|#Level:Host|#hostname:pressler-dell,timestamp:1641727653
2022-01-09T12:27:33,169 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:39.8|#Level:Host|#hostname:pressler-dell,timestamp:1641727653
2022-01-09T12:27:33,235 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 741
2022-01-09T12:27:33,235 [INFO ] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 741
2022-01-09T12:27:33,236 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:27:33,236 [DEBUG] W-9000-scalenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-scalenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:27:33,236 [INFO ] W-9000-scalenet_1.0 TS_METRICS - W-9000-scalenet_1.0.ms:1711|#Level:Host|#hostname:pressler-dell,timestamp:1641727653
2022-01-09T12:27:33,236 [INFO ] W-9000-scalenet_1.0 TS_METRICS - WorkerThreadTime.ms:49|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:27:33,636 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9001
2022-01-09T12:27:33,637 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - [PID]70946
2022-01-09T12:27:33,638 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Torch worker started.
2022-01-09T12:27:33,638 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:27:33,638 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change null -> WORKER_STARTED
2022-01-09T12:27:33,638 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Python runtime: 3.9.9
2022-01-09T12:27:33,638 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:27:33,638 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2022-01-09T12:27:33,640 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727653640
2022-01-09T12:27:33,640 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727653640
2022-01-09T12:27:33,640 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9001.
2022-01-09T12:27:33,669 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - model_name: yolov5, batchSize: 1
2022-01-09T12:27:39,838 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG - /home/pressler/.local/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
2022-01-09T12:27:39,839 [WARN ] W-9001-yolov5_0.1-stderr MODEL_LOG -   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
2022-01-09T12:27:39,863 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:27:39,864 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 232 layers, 7459581 parameters, 0 gradients, 17.5 GFLOPS
2022-01-09T12:27:40,316 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:27:40,316 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Fusing layers... 
2022-01-09T12:27:40,316 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model Summary: 224 layers, 7056607 parameters, 7056607 gradients, 16.3 GFLOPS
2022-01-09T12:27:40,320 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6650
2022-01-09T12:27:40,320 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6650
2022-01-09T12:27:40,320 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:27:40,320 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - W-9001-yolov5_0.1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-01-09T12:27:40,320 [INFO ] W-9001-yolov5_0.1 TS_METRICS - W-9001-yolov5_0.1.ms:7539|#Level:Host|#hostname:pressler-dell,timestamp:1641727660
2022-01-09T12:27:40,321 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:31|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:27:40,323 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727660322
2022-01-09T12:27:40,323 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727660322
2022-01-09T12:27:40,324 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Adding autoShape... 
2022-01-09T12:27:40,328 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Model file /tmp/models/eb76ef13592c40059f80e44050f05796/yolov5s.pt loaded successfully
2022-01-09T12:27:40,332 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641727660
2022-01-09T12:27:40,496 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 166
2022-01-09T12:27:40,495 [INFO ] W-9001-yolov5_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:163.41|#ModelName:yolov5,Level:Model|#hostname:pressler-dell,requestID:fa74318b-efc6-4f8d-afc1-c29a86a3bfe7,timestamp:1641727660
2022-01-09T12:27:40,496 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 166
2022-01-09T12:27:40,500 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:54614 "POST /predictions/yolov5 HTTP/1.1" 200 5782
2022-01-09T12:27:40,498 [INFO ] W-9001-yolov5_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:163.52|#ModelName:yolov5,Level:Model|#hostname:pressler-dell,requestID:fa74318b-efc6-4f8d-afc1-c29a86a3bfe7,timestamp:1641727660
2022-01-09T12:27:40,501 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:27:40,501 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 5366758664, Backend time ns: 178315106
2022-01-09T12:27:40,501 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 5366758664, Backend time ns: 178315106
2022-01-09T12:27:40,501 [INFO ] W-9001-yolov5_0.1 TS_METRICS - QueueTime.ms:5366|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:27:40,501 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:13|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:28:01,292 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727681292
2022-01-09T12:28:01,292 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727681292
2022-01-09T12:28:01,322 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641727681
2022-01-09T12:28:01,607 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 287
2022-01-09T12:28:01,607 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 287
2022-01-09T12:28:01,608 [INFO ] W-9001-yolov5_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:285.02|#ModelName:yolov5,Level:Model|#hostname:pressler-dell,requestID:494c448d-0fc3-4f0b-a607-10cacc6a8159,timestamp:1641727681
2022-01-09T12:28:01,608 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:54614 "POST /predictions/yolov5 HTTP/1.1" 200 417
2022-01-09T12:28:01,608 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:28:01,608 [INFO ] W-9001-yolov5_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:285.12|#ModelName:yolov5,Level:Model|#hostname:pressler-dell,requestID:494c448d-0fc3-4f0b-a607-10cacc6a8159,timestamp:1641727681
2022-01-09T12:28:01,609 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 132436, Backend time ns: 316545060
2022-01-09T12:28:01,609 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 132436, Backend time ns: 316545060
2022-01-09T12:28:01,609 [INFO ] W-9001-yolov5_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:28:01,609 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:30|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:28:33,144 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727713
2022-01-09T12:28:33,145 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.27028274536133|#Level:Host|#hostname:pressler-dell,timestamp:1641727713
2022-01-09T12:28:33,145 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.983455657959|#Level:Host|#hostname:pressler-dell,timestamp:1641727713
2022-01-09T12:28:33,146 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727713
2022-01-09T12:28:33,146 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17150.90625|#Level:Host|#hostname:pressler-dell,timestamp:1641727713
2022-01-09T12:28:33,147 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11309.265625|#Level:Host|#hostname:pressler-dell,timestamp:1641727713
2022-01-09T12:28:33,147 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:46.3|#Level:Host|#hostname:pressler-dell,timestamp:1641727713
2022-01-09T12:28:41,309 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727721309
2022-01-09T12:28:41,309 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727721309
2022-01-09T12:28:41,329 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641727721
2022-01-09T12:28:41,770 [INFO ] W-9001-yolov5_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:439.5|#ModelName:yolov5,Level:Model|#hostname:pressler-dell,requestID:311a9b35-6431-4c16-bf3e-18c4a09d7640,timestamp:1641727721
2022-01-09T12:28:41,771 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 444
2022-01-09T12:28:41,771 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 444
2022-01-09T12:28:41,771 [INFO ] W-9001-yolov5_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:439.64|#ModelName:yolov5,Level:Model|#hostname:pressler-dell,requestID:311a9b35-6431-4c16-bf3e-18c4a09d7640,timestamp:1641727721
2022-01-09T12:28:41,771 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:54614 "POST /predictions/yolov5 HTTP/1.1" 200 509
2022-01-09T12:28:41,771 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:28:41,772 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 170140, Backend time ns: 462083098
2022-01-09T12:28:41,772 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 170140, Backend time ns: 462083098
2022-01-09T12:28:41,772 [INFO ] W-9001-yolov5_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:28:41,772 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:19|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:29:33,161 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727773
2022-01-09T12:29:33,161 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.26904296875|#Level:Host|#hostname:pressler-dell,timestamp:1641727773
2022-01-09T12:29:33,161 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9846954345703|#Level:Host|#hostname:pressler-dell,timestamp:1641727773
2022-01-09T12:29:33,161 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727773
2022-01-09T12:29:33,162 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:16875.88671875|#Level:Host|#hostname:pressler-dell,timestamp:1641727773
2022-01-09T12:29:33,162 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11406.34765625|#Level:Host|#hostname:pressler-dell,timestamp:1641727773
2022-01-09T12:29:33,162 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:47.1|#Level:Host|#hostname:pressler-dell,timestamp:1641727773
2022-01-09T12:29:45,669 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727785669
2022-01-09T12:29:45,669 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727785669
2022-01-09T12:29:45,707 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641727785
2022-01-09T12:29:46,077 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 370
2022-01-09T12:29:46,077 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 370
2022-01-09T12:29:46,077 [INFO ] W-9001-yolov5_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:369.46|#ModelName:yolov5,Level:Model|#hostname:pressler-dell,requestID:90eee15b-2f7e-4ed7-ace7-17ad07e6f020,timestamp:1641727786
2022-01-09T12:29:46,079 [INFO ] W-9001-yolov5_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:369.54|#ModelName:yolov5,Level:Model|#hostname:pressler-dell,requestID:90eee15b-2f7e-4ed7-ace7-17ad07e6f020,timestamp:1641727786
2022-01-09T12:29:46,078 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:54614 "POST /predictions/yolov5 HTTP/1.1" 200 472
2022-01-09T12:29:46,080 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:29:46,080 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 142725, Backend time ns: 411295895
2022-01-09T12:29:46,080 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 142725, Backend time ns: 411295895
2022-01-09T12:29:46,080 [INFO ] W-9001-yolov5_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:29:46,081 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:42|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:29:51,797 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727791797
2022-01-09T12:29:51,797 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1641727791797
2022-01-09T12:29:51,801 [INFO ] W-9001-yolov5_0.1-stdout MODEL_LOG - Backend received inference at: 1641727791
2022-01-09T12:29:51,896 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 97
2022-01-09T12:29:51,896 [INFO ] W-9001-yolov5_0.1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 97
2022-01-09T12:29:51,897 [INFO ] W-9001-yolov5_0.1-stdout MODEL_METRICS - HandlerTime.Milliseconds:96.85|#ModelName:yolov5,Level:Model|#hostname:pressler-dell,requestID:3eed8676-414b-4ac6-9da3-8368df7fafe1,timestamp:1641727791
2022-01-09T12:29:51,897 [INFO ] W-9001-yolov5_0.1 ACCESS_LOG - /127.0.0.1:54614 "POST /predictions/yolov5 HTTP/1.1" 200 101
2022-01-09T12:29:51,897 [INFO ] W-9001-yolov5_0.1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:29:51,897 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 127176, Backend time ns: 100463823
2022-01-09T12:29:51,897 [DEBUG] W-9001-yolov5_0.1 org.pytorch.serve.job.Job - Waiting time ns: 127176, Backend time ns: 100463823
2022-01-09T12:29:51,898 [INFO ] W-9001-yolov5_0.1-stdout MODEL_METRICS - PredictionTime.Milliseconds:96.99|#ModelName:yolov5,Level:Model|#hostname:pressler-dell,requestID:3eed8676-414b-4ac6-9da3-8368df7fafe1,timestamp:1641727791
2022-01-09T12:29:51,898 [INFO ] W-9001-yolov5_0.1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:29:51,899 [INFO ] W-9001-yolov5_0.1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:pressler-dell,timestamp:null
2022-01-09T12:30:33,144 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727833
2022-01-09T12:30:33,146 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.26916885375977|#Level:Host|#hostname:pressler-dell,timestamp:1641727833
2022-01-09T12:30:33,146 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.98456954956055|#Level:Host|#hostname:pressler-dell,timestamp:1641727833
2022-01-09T12:30:33,147 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727833
2022-01-09T12:30:33,147 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17192.71484375|#Level:Host|#hostname:pressler-dell,timestamp:1641727833
2022-01-09T12:30:33,147 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11324.515625|#Level:Host|#hostname:pressler-dell,timestamp:1641727833
2022-01-09T12:30:33,148 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:46.1|#Level:Host|#hostname:pressler-dell,timestamp:1641727833
2022-01-09T12:31:33,144 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727893
2022-01-09T12:31:33,144 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.26912689208984|#Level:Host|#hostname:pressler-dell,timestamp:1641727893
2022-01-09T12:31:33,145 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.98461151123047|#Level:Host|#hostname:pressler-dell,timestamp:1641727893
2022-01-09T12:31:33,146 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727893
2022-01-09T12:31:33,146 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17197.63671875|#Level:Host|#hostname:pressler-dell,timestamp:1641727893
2022-01-09T12:31:33,147 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11320.2109375|#Level:Host|#hostname:pressler-dell,timestamp:1641727893
2022-01-09T12:31:33,147 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:46.1|#Level:Host|#hostname:pressler-dell,timestamp:1641727893
2022-01-09T12:32:33,158 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:pressler-dell,timestamp:1641727953
2022-01-09T12:32:33,158 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:76.26908874511719|#Level:Host|#hostname:pressler-dell,timestamp:1641727953
2022-01-09T12:32:33,159 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:421.9846496582031|#Level:Host|#hostname:pressler-dell,timestamp:1641727953
2022-01-09T12:32:33,159 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:84.7|#Level:Host|#hostname:pressler-dell,timestamp:1641727953
2022-01-09T12:32:33,160 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:17166.0625|#Level:Host|#hostname:pressler-dell,timestamp:1641727953
2022-01-09T12:32:33,161 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:11319.14453125|#Level:Host|#hostname:pressler-dell,timestamp:1641727953
2022-01-09T12:32:33,162 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:46.2|#Level:Host|#hostname:pressler-dell,timestamp:1641727953
